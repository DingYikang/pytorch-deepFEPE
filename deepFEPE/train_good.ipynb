{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize superpoint and deep fundamental matrix\n",
    "- based on deep_F_baselineEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\n",
    "#     \"/home/yyjau/Documents/deepSfm/torch-batch-svd\"\n",
    "# )  # path for youyi in theia\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_DEVICE_ORDER']=“PCI_BUS_ID”\n",
    "# os.environ[“CUDA_VISIBLE_DEVICES”]=“5”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import yaml\n",
    "import os, sys\n",
    "from path import Path\n",
    "import copy\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import cv2\n",
    "import time\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from utils.logging import *\n",
    "import argparse\n",
    "from pebble import ProcessPool\n",
    "import multiprocessing as mp\n",
    "ratio_CPU = 0.5\n",
    "default_number_of_process = int(ratio_CPU * mp.cpu_count())\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from settings import EXPER_PATH\n",
    "\n",
    "\n",
    "## loaders: data, model, pretrained model\n",
    "from utils.loader import dataLoader, modelLoader, pretrainedLoader_net, pretrainedLoader_opt\n",
    "sys.path.append('/home/ruizhu/Documents/Projects/kitti_instance_RGBD_utils')\n",
    "import dsac_tools.utils_F as utils_F # If cannot find: export KITTI_UTILS_PATH='/home/ruizhu/Documents/Projects/kitti_instance_RGBD_utils'\n",
    "import dsac_tools.utils_opencv as utils_opencv # If cannot find: export KITTI_UTILS_PATH='/home/ruizhu/Documents/Projects/kitti_instance_RGBD_utils'\n",
    "import dsac_tools.utils_vis as utils_vis # If cannot find: export KITTI_UTILS_PATH='/home/ruizhu/Documents/Projects/kitti_instance_RGBD_utils'\n",
    "import dsac_tools.utils_misc as utils_misc # If cannot find: export KITTI_UTILS_PATH='/home/ruizhu/Documents/Projects/kitti_instance_RGBD_utils'\n",
    "import dsac_tools.utils_geo as utils_geo # If cannot find: export KITTI_UTILS_PATH='/home/ruizhu/Documents/Projects/kitti_instance_RGBD_utils'\n",
    "\n",
    "from train_good_utils import get_all_loss, val_rt, get_all_loss_DeepF\n",
    "\n",
    "# from utils.utils import tensor2array, save_checkpoint, load_checkpoint, save_path_formatter\n",
    "# from utils.utils import getWriterPath\n",
    "# from utils.utils import saveLoss\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "logging.basicConfig(format='[%(asctime)s %(levelname)s] %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S', level=logging.DEBUG)\n",
    "\n",
    "# add parser\n",
    "parser = argparse.ArgumentParser(description='Foo')\n",
    "\n",
    "# Training command\n",
    "parser.add_argument('config', type=str)\n",
    "parser.add_argument('exper_name', type=str)\n",
    "# args = parser.parse_args('configs/apollo_corr_baseline.yaml baselineEval_visKitti'.split())\n",
    "# args = parser.parse_args('configs/apollo_train_corr_baseline.yaml baselineEval_visKitti'.split())\n",
    "args = parser.parse_args('configs/apollo_train_corr_baselineEval.yaml baselineEval_visKitti'.split())\n",
    "# args = parser.parse_args('configs/kitti_corr_baselineEval.yaml baselineEval_visKitti'.split())\n",
    "# args = parser.parse_args('configs/euroc_corr_baselineEval.yaml baselineEval_visKitti'.split())\n",
    "print(args)\n",
    "\n",
    "with open(args.config, 'r') as f:\n",
    "    config = yaml.load(f)\n",
    "# EXPER_PATH from settings.py\n",
    "output_dir = os.path.join(EXPER_PATH, args.exper_name)\n",
    "print(output_dir)\n",
    "print(f\"config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['data']['batch_size'] = 1\n",
    "# config['data']['read_what']['with_imgs'] = False\n",
    "# config['training']['pretrained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # config['training']['pretrained'] = 'logs/mm1-testCondition_lossRes_regCondClip1e+4Balance1e-6/checkpoints/superPointNet_96000_checkpoint.pth.tar'\n",
    "# # config['training']['pretrained'] = 'logs/mm1-retro_clamp02_normHW/checkpoints/superPointNet_111500_checkpoint.pth.tar'\n",
    "# # config['training']['pretrained'] = 'logs/mm2-retro_clamp02_normHW_offset/checkpoints/superPointNet_45500_checkpoint.pth.tar'\n",
    "# # config['training']['pretrained'] = 'logs/mm1-retro_clamp02_normHW_finetuneQtLoss-resetIter-first1000DeepFLoss_balanceQ10t1_lr1e-4/checkpoints/superPointNet_185000_checkpoint.pth.tar'\n",
    "# # config['training']['pretrained'] = 'logs/test_pose_from_start_3800+/checkpoints/superPointNet_29800_checkpoint.pth.tar'\n",
    "# config['training']['pretrained'] = 'logs/baselineTrain_sp_deepF_kitti_qtLoss_v0/checkpoints/deepFNet_30000_checkpoint.pth.tar'\n",
    "\n",
    "# # edit data root\n",
    "# config['data']['dump_root'] = '/home/ruizhu/Documents/Datasets/kitti/kitti_dump/odo_corr_dump_siftIdx_npy_delta1235810_full'\n",
    "\n",
    "# # config['training']['pretrained'] = 'logs/mm2-retro_clamp02_noSVDNormalize/checkpoints/superPointNet_87500_checkpoint.pth.tar'\n",
    "\n",
    "# config['data']['batch_size'] = 1\n",
    "# # config['data']['dump_root'] = '/home/ruizhu/Documents/Datasets/kitti/kitti_dump/odo_corr_dump_siftIdx_npy_delta1235810_full_deepFSplitRe'\n",
    "# config['data']['delta_ij'] = 1\n",
    "\n",
    "# config['data']['read_what']['with_des'] = False\n",
    "# config['data']['read_what']['with_quality'] = False # True # True\n",
    "# # config['data']['read_what']['with_sift_des'] = True\n",
    "# config['model']['if_img_feat'] = False\n",
    "# config['model']['if_quality'] = False\n",
    "# config['model']['if_learn_offsets'] = False\n",
    "# config['model']['if_qt_loss'] = False\n",
    "# config['data']['read_what']['with_X'] = True\n",
    "# config['model']['if_tri_depth'] = False\n",
    "# config['model']['if_sample_loss'] = False\n",
    "\n",
    "# config['training']['reproduce'] = False\n",
    "# # config['model']['name'] = 'GoodCorresNet_layers_deepF_singleSample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (only need to do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info('train on device: %s', device)\n",
    "args.test = True\n",
    "# writer = SummaryWriter(getWriterPath(task='train_good', exper_name=args.exper_name, date=True))\n",
    "\n",
    "# data loading\n",
    "assert config['data']['sequence_length']==2, \"Sorry dude, we are only supporting two-frame setting for now.\"\n",
    "assert (config['data']['read_what']['with_X'] and config['data']['batch_size']==1) or (not config['data']['read_what']['with_X']), 'We are not suppoting batching lidar Xs with batch_size>1 yet!'\n",
    "val = 'test' if args.test else 'val' \n",
    "data = dataLoader(config, dataset=config['data']['dataset'], val=val, warp_input=True, val_shuffle=False)\n",
    "train_loader, val_loader = data['train_loader'], data['val_loader']\n",
    "logging.info('+++[Dataset]+++ train split size %d in %d batches, val split size %d in %d batches'%\\\n",
    "    (len(train_loader)*config['data']['batch_size'], len(train_loader), len(val_loader)*config['data']['batch_size'], len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data['val_loader'].dataset.samples\n",
    "print(f\"samples: {len(samples)}\")\n",
    "idx = 3\n",
    "print(f\"samples: {samples[idx]}\")\n",
    "sample = samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for j, sample in enumerate(val_loader):\n",
    "    image_0 = sample['imgs'][0]\n",
    "    print(f\"gamma: {sample['gamma'][0]}, image: {type(image)}, {image.shape}, {image.max()}\")\n",
    "#     plt.imshow(image.squeeze().numpy()/255)\n",
    "    image_1 = sample['imgs'][1]\n",
    "    image_1_gray = cv2.cvtColor(image_1, cv2.COLOR_RGB2GRAY)\n",
    "#     plt.show()\n",
    "    image = image_0 + 0\n",
    "    image[0] += image_1_gray\n",
    "    plt.imshow(image.squeeze().numpy()/255)\n",
    "    plt.show()\n",
    "    if j >= 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_pose_cam_to_body(relative_scene_pose, Rt_cam2_gt):\n",
    "    \"\"\" transform the camera pose from camera coordinate to body coordinate\n",
    "    \"\"\"\n",
    "    relative_scene_pose = (\n",
    "        np.linalg.inv(Rt_cam2_gt) \n",
    "        @ relative_scene_pose\n",
    "        @ Rt_cam2_gt\n",
    "    )\n",
    "    return relative_scene_pose\n",
    "\n",
    "M_estW = sample['cam_poses'][0]\n",
    "M_estW = sample['cam_poses'][0]\n",
    "Rt_cam2_gt_np = sample['Rt_cam2_gt']\n",
    "\n",
    "# M_estW_body = relative_pose_cam_to_body(M_estW, Rt_cam2_gt_np)\n",
    "M_estW_body = M_estW\n",
    "print(f\"M_estW_body: {M_estW_body}\")\n",
    "from numpy.linalg import inv\n",
    "print(f\"M_estW_body inv: {inv(M_estW_body)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# # model loading\n",
    "# img_zoom_xy = (config['data']['preprocessing']['resize'][1]/config['data']['image']['size'][1], config['data']['preprocessing']['resize'][0]/config['data']['image']['size'][0])\n",
    "\n",
    "# # model_params = {'depth': config['model']['depth'], 'clamp_at':config['model']['clamp_at'], 'in_channels': 4, 'num_seg_classes': 1, 'with_transform': False, 'with_instance_norm': True}\n",
    "# model_params = {'depth': config['model']['depth'],  'img_zoom_xy': img_zoom_xy, 'image_size': config['data']['image']['size'], \\\n",
    "#     'quality_size': config['model']['quality_size'], 'if_quality': config['model']['if_quality'], \\\n",
    "#     'if_img_des_to_pointnet': config['model']['if_img_des_to_pointnet'], 'if_goodCorresArch': config['model']['if_goodCorresArch'], 'if_img_feat': config['model']['if_img_feat'], \\\n",
    "#     'if_cpu_svd': config['model']['if_cpu_svd'], 'if_learn_offsets': config['model']['if_learn_offsets'], 'if_sample_loss': config['model']['if_sample_loss']}\n",
    "\n",
    "# # model_params = {'depth': config['model']['depth'],  'zoom_xy': zoom_xy, 'quality_size': config['model']['quality_size'], \\\n",
    "# #     'if_quality': config['model']['if_quality'], 'if_des': config['model']['if_des'], 'if_goodCorresArch': config['model']['if_goodCorresArch'], 'if_img_feat': config['model']['if_img_feat']}\n",
    "# net_eval = modelLoader(config['model']['name'], model_params)\n",
    "\n",
    "# logging.info('+++[Train]+++ setting adam solver')\n",
    "# n_iter = 0\n",
    "# n_iter_val = 0\n",
    "# epoch = 0\n",
    "\n",
    "# ## load pretrained\n",
    "# checkpoint_path = config['training']['pretrained']\n",
    "# print(checkpoint_path)\n",
    "# checkpoint_mode = '' if checkpoint_path[-3:] == 'pth' else 'full'\n",
    "# logging.info('Loading net: path: %s, mode: %s'%(checkpoint_path, checkpoint_mode))\n",
    "# net_eval, n_iter, _ = pretrainedLoader_net(net_eval, n_iter, checkpoint_path, mode=checkpoint_mode, full_path=True)\n",
    "\n",
    "# logging.info(\"+++[Train]+++ Let's use %d GPUs!\"%torch.cuda.device_count())\n",
    "# net_eval = net_eval.to(device)\n",
    "# # net = nn.DataParallel(net)\n",
    "# optimizer = optim.Adam(net_eval.parameters(), lr=config['training']['learning_rate'])\n",
    "# logging.info('Loading optimizer: path: %s, mode: %s'%(checkpoint_path, checkpoint_mode))\n",
    "# optimizer, n_iter, _ = pretrainedLoader_opt(optimizer, n_iter, checkpoint_path, mode=checkpoint_mode, full_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model loading\n",
    "from train_good_corr_4_vals_goodF_baseline import prepare_model\n",
    "\n",
    "img_zoom_xy = (\n",
    "    config[\"data\"][\"preprocessing\"][\"resize\"][1]\n",
    "    / config[\"data\"][\"image\"][\"size\"][1],\n",
    "    config[\"data\"][\"preprocessing\"][\"resize\"][0]\n",
    "    / config[\"data\"][\"image\"][\"size\"][0],\n",
    ")\n",
    "model_params = {\n",
    "    \"depth\": config[\"model\"][\"depth\"],\n",
    "    \"img_zoom_xy\": img_zoom_xy,\n",
    "    \"image_size\": config[\"data\"][\"image\"][\"size\"],\n",
    "    \"quality_size\": config[\"model\"][\"quality_size\"],\n",
    "    \"if_quality\": config[\"model\"][\"if_quality\"],\n",
    "    \"if_img_des_to_pointnet\": config[\"model\"][\"if_img_des_to_pointnet\"],\n",
    "    \"if_goodCorresArch\": config[\"model\"][\"if_goodCorresArch\"],\n",
    "    \"if_img_feat\": config[\"model\"][\"if_img_feat\"],\n",
    "    \"if_cpu_svd\": config[\"model\"][\"if_cpu_svd\"],\n",
    "    \"if_learn_offsets\": config[\"model\"][\"if_learn_offsets\"],\n",
    "    \"if_tri_depth\": config[\"model\"][\"if_tri_depth\"],\n",
    "    \"if_sample_loss\": config[\"model\"][\"if_sample_loss\"],\n",
    "}\n",
    "net = modelLoader(config[\"model\"][\"name\"], **model_params)\n",
    "net, optimizer, n_iter, n_iter_val = prepare_model(\n",
    "    config, net, device, n_iter=0, n_iter_val=0, net_postfix=''\n",
    ")\n",
    "net_eval = net.to(device)\n",
    "\n",
    "# load sp\n",
    "if config['model']['if_SP']:\n",
    "    SP_params = {\n",
    "        \"out_num_points\": 2000,\n",
    "        \"patch_size\": 5,\n",
    "        \"device\": device,\n",
    "        \"nms_dist\": 4,\n",
    "        \"conf_thresh\": 0.015,\n",
    "    }\n",
    "    from models.model_utils import SuperPointNet_process\n",
    "    from models.model_wrap import PointTracker\n",
    "    from models.SuperPointNet_gauss2 import *\n",
    "    SP_processer = SuperPointNet_process(**SP_params)\n",
    "    SP_tracker = PointTracker(max_length=2, nn_thresh=1.2)\n",
    "    net_SP = SuperPointNet_gauss2()\n",
    "\n",
    "    net_SP, optimizer_SP, n_iter_SP, n_iter_val_SP = prepare_model(\n",
    "        config, net_SP, device, n_iter=0, n_iter_val=0, net_postfix='_SP', train=False\n",
    "    )\n",
    "    \n",
    "    logging.info(\"+++[Train]+++  training superpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create subgraph for combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "frame_list = [0, 100, 200, 300]\n",
    "prefix = 'Sp-Df-fp-end-k'\n",
    "plot_folder = 'plots/'\n",
    "plot_name = 'corr_all_'\n",
    "image_name = [f\"{plot_folder}{plot_name}{prefix}{i:06}_{(i+1):06}.png\" for i in frame_list]\n",
    "print(image_name)\n",
    "img_num = 4\n",
    "\n",
    "image_datas = []\n",
    "for i, file in enumerate(image_name):\n",
    "    img = cv2.imread(file)\n",
    "    image_datas.append(img)\n",
    "    print(f\"read {i}: {file}\")\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(2,2, figsize=(48, 12))\n",
    "for i in range(img_num):\n",
    "    axarr[int(i/2),i%2].imshow(image_datas[i])\n",
    "    axarr[int(i/2),i%2].axis('off')\n",
    "#     axarr[i/2,i%2].imshow(image_datas[1])\n",
    "#     axarr[1,0].imshow(image_datas[2])\n",
    "#     axarr[1,1].imshow(image_datas[3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_agent.net_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval one sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### before end-to-end training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kitti\n",
    "config['training']['pretrained'] = 'logs/baselineTrain_deepF_kitti_fLoss_v1/checkpoints/deepFNet_30000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = 'logs/superpoint_kitti_heat2_0/checkpoints/superPointNet_50000_checkpoint.pth.tar'\n",
    "model_name = 'Sp-Df-fp-k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apollo\n",
    "config['training']['pretrained'] = 'logs/baselineTrain_deepF_apolloFLoss_v3/checkpoints/deepFNet_60000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = 'logs/superpoint_apollo_v1/checkpoints/superPointNet_40000_checkpoint.pth.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kitti end-2-end (best)\n",
    "config['training']['pretrained'] = 'logs/baselineTrain_kittiSp_deepF_end_kittiFLossPoseLoss_v1_freezeSp/checkpoints/deepFNet_38000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = 'logs/baselineTrain_kittiSp_deepF_end_kittiFLossPoseLoss_v1_freezeSp/checkpoints/superPointNet_38000_checkpoint.pth.tar'\n",
    "config['model']['if_SP'] = True\n",
    "model_name = 'Sp-Df-fp-end-k' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apollo end-to-end\n",
    "config['training']['pretrained'] = 'logs/baselineTrain_apolloSp_apolloDeepF_end_apolloFLossPoseLoss_v1_freezeSp_poseLoss_cont/checkpoints/deepFNet_22000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = 'logs/baselineTrain_apolloSp_apolloDeepF_end_apolloFLossPoseLoss_v1_freezeSp_poseLoss_cont/checkpoints/superPointNet_22000_checkpoint.pth.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift \n",
    "config['training']['pretrained'] = 'logs/baselineTrain_sift_deepF_poseLoss_v0/checkpoints/deepFNet_40000_checkpoint.pth.tar'\n",
    "config['model']['if_SP'] = False\n",
    "config['training']['pretrained_SP'] = ''\n",
    "model_name = 'Si-Df-fp-k' #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kitti freeze deepF\n",
    "config['training']['pretrained'] = f'logs/baselineTrain_kittiSp_deepF_kittiFLoss_v0/checkpoints/deepFNet_18000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = f'logs/superpoint_kitti_heat2_0/checkpoints/superPointNet_50000_checkpoint.pth.tar'        \n",
    "config['model']['if_SP'] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # config['training']['pretrained'] = 'logs/baselineTrain_deepF_kitti_fLoss_v1/checkpoints/deepFNet_30000_checkpoint.pth.tar'\n",
    "# config['training']['pretrained'] = 'logs/baselineTrain_DeepF_apolloFLoss_fromKitti_v3/checkpoints/deepFNet_30000_checkpoint.pth.tar'\n",
    "# config['model']['if_SP'] = True; logging.info(f\"not using superpoint!\")\n",
    "# # config['model']['if_SP'] = True; logging.info(f\"using superpoint!\")\n",
    "\n",
    "# config['training']['pretrained_SP'] = 'logs/superpoint_spollo_v0/checkpoints/superPointNet_50000_checkpoint.pth.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j, sample in enumerate(val_loader):\n",
    "#     print(f\"sample: {list(sample)}\")\n",
    "#     if j==0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.eval_tools import Val_pipeline_frontend\n",
    "\n",
    "# plot_epipolar_list=[\"mask_conf\", \"mask_epi_dist_gt\"]\n",
    "plot_epipolar_list=[\"mask_conf\"]\n",
    "plot_corr_list=[\"\"]  # \"all\"\n",
    "val_agent = Val_pipeline_frontend(config, device=device)\n",
    "# val_agent.add_net('deepF', net)\n",
    "# val_agent.add_net('superpointNet', net_SP)\n",
    "val_agent.load_net_deepF(name='net_deepF')\n",
    "if config['model']['if_SP']: val_agent.load_net_SP()\n",
    "val_agent.net_toeval() \n",
    "\n",
    "num_list = []\n",
    "iter_max = 500 # 1000\n",
    "# iter_list = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "# iter_list = np.arange(27)*100\n",
    "# iter_list = [171, 1775, 2591, 2748]  ## ours good!\n",
    "# iter_list = [1466, 1599, 2241]  ## ours bad!\n",
    "# iter_list = [1119, 1510, 2317]  ## ours rotations!\n",
    "# iter_list = [1605, 2225, 1518]  ## ours translations!\n",
    "iter_dict = {\n",
    "#     'test': [0, 5],\n",
    "#     'good': [171, 1775, 2591, 2748],  ## ours good!\n",
    "#     'good': [171, 2573, 2741],  ## ours good!\n",
    "#     'bad': [2450, 2758, 2464],  ## ours bad!\n",
    "#     'rot': [1493, 1494, 1495, 1496, 657, 658, 659, 923, 924, 925],  ## ours rotations!\n",
    "#     'rot': [267],  ## ours rotations!\n",
    "#     'trans': [1605, 2225, 1518]  ## ours translations!\n",
    "}\n",
    "## 2020/02/27 output all the frames\n",
    "iter_dict = {\n",
    "    'all_fr': np.arange(iter_max),\n",
    "}\n",
    "\n",
    "iter_dict_rev = {}\n",
    "for i, en in enumerate(iter_dict):\n",
    "    iters = iter_dict[en]\n",
    "    for it in iters:\n",
    "        iter_dict_rev[it] = en\n",
    "print(f\"iter_dict_rev: {iter_dict_rev}\")\n",
    "\n",
    "\n",
    "# iter_list = [200]\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_folder = 'plots/vis_paper/'+model_name+\"_apo\"\n",
    "print(f\"save base_folder: {base_folder}\")\n",
    "\n",
    "for j, sample in tqdm(enumerate(val_loader)):\n",
    "#     val_agent.eval_one_sample(sample)\n",
    "#     if j in iter_list:\n",
    "\n",
    "    if j in iter_dict_rev:\n",
    "        prefix = f'{model_name}_{iter_dict_rev[j]}_{j}' #  \n",
    "        print(sample['scene_name'], sample['frame_ids'], sample['img_zoom_xy'])\n",
    "        logging.info(f\"eval {j}, prefix: {prefix}\")\n",
    "        val_agent.run_eval(sample, plot_epipolar_list=plot_epipolar_list, \n",
    "                           plot_corr_list=plot_corr_list, prefix=prefix, \n",
    "                           save=True, title=False, base_folder=base_folder)\n",
    "\n",
    "\n",
    "    if j >= iter_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "171 in iter_dict_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After end-to-end training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training']['pretrained'] = 'logs/baselineTrain_sp_deepF_kitti_qtLoss_v3/checkpoints/deepFNet_8000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = 'logs/baselineTrain_sp_deepF_kitti_qtLoss_v3/checkpoints/superPointNet_8000_checkpoint.pth.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training']['pretrained'] = 'logs/baselineTrain_apolloSp_apolloDeepF_apolloPoseLoss_v0/checkpoints/deepFNet_9000_checkpoint.pth.tar'\n",
    "config['training']['pretrained_SP'] = 'logs/baselineTrain_apolloSp_apolloDeepF_apolloPoseLoss_v0/checkpoints/superPointNet_9000_checkpoint.pth.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.eval_tools import Val_pipeline_frontend\n",
    "\n",
    "val_agent = Val_pipeline_frontend(config, device=device)\n",
    "# val_agent.add_net('deepF', net)\n",
    "# val_agent.add_net('superpointNet', net_SP)\n",
    "val_agent.load_net_deepF(name='net_deepF')\n",
    "val_agent.load_net_SP()\n",
    "val_agent.net_toeval() \n",
    "\n",
    "num_list = []\n",
    "iter_max = 3\n",
    "for j, sample in enumerate(val_loader):\n",
    "    print(sample['scene_name'], sample['frame_ids'])\n",
    "#     val_agent.eval_one_sample(sample)\n",
    "    \n",
    "    val_agent.run_eval(sample)\n",
    "\n",
    "    if j >= iter_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_velo = sample['pts1_velo'].squeeze().numpy()[:, :2]\n",
    "# x2_velo = sample['pts2_velo'].squeeze().numpy()[:, :2]\n",
    "\n",
    "# utils_vis.draw_corr(img1_rgb, img2_rgb, x1[mask_sample], x2[mask_sample], linewidth=2., title='Sample of 100 corres.')\n",
    "# utils_vis.draw_corr(img1_rgb, img2_rgb, x1_velo, x2_velo, linewidth=2., title='Sample of 100 corres.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How points move when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.eval_tools import Val_pipeline_frontend\n",
    "\n",
    "def change_config(config, iter=1000, mode=0): # 8000 the best\n",
    "    if mode == 0:\n",
    "        config['training']['pretrained'] = f'logs/baselineTrain_sp_deepF_kitti_qtLoss_v3/checkpoints/deepFNet_{iter}_checkpoint.pth.tar'\n",
    "        config['training']['pretrained_SP'] = f'logs/baselineTrain_sp_deepF_kitti_qtLoss_v3/checkpoints/superPointNet_{iter}_checkpoint.pth.tar'\n",
    "    elif mode == 1: # only change the superpointnet\n",
    "        config['training']['pretrained'] = 'logs/baselineTrain_deepF_apolloFLoss_v3/checkpoints/deepFNet_60000_checkpoint.pth.tar'\n",
    "        config['training']['pretrained_SP'] = f'logs/superpoint_apollo_v1/checkpoints/superPointNet_{iter}_checkpoint.pth.tar'\n",
    "    elif mode == 2:\n",
    "        config['training']['pretrained'] = 'logs/baselineTrain_deepF_kitti_fLoss_v1/checkpoints/deepFNet_30000_checkpoint.pth.tar'\n",
    "        config['training']['pretrained_SP'] = f'logs/superpoint_kitti_heat2_0/checkpoints/superPointNet_{iter}_checkpoint.pth.tar'\n",
    "    elif mode == 3: \n",
    "        config['training']['pretrained'] = f'logs/baselineTrain_sp_deepF_kitti_qtLoss_v3/checkpoints/deepFNet_8000_checkpoint.pth.tar'\n",
    "        config['training']['pretrained_SP'] = f'logs/baselineTrain_sp_deepF_kitti_qtLoss_v3/checkpoints/superPointNet_{iter}_checkpoint.pth.tar'        \n",
    "    elif mode == 4:  # 11/2 only train sp\n",
    "        config['training']['pretrained'] = f'logs/baselineTrain_kittiSp_deepF_end_kittiFLoss_freezeDeepF_v0/checkpoints/deepFNet_8000_checkpoint.pth.tar'\n",
    "        config['training']['pretrained_SP'] = f'logs/baselineTrain_kittiSp_deepF_end_kittiFLoss_freezeDeepF_v0/checkpoints/superPointNet_{iter}_checkpoint.pth.tar'        \n",
    "\n",
    "\n",
    "        \n",
    "    return config\n",
    "\n",
    "\n",
    "config = change_config(config, iter=1000)    \n",
    "plot_epipolar_list=[\"\"] # [\"mask_conf\", \"mask_epi_dist_gt\"]\n",
    "plot_corr_list=[\"random\"]  # \"all\"\n",
    "\n",
    "# def run_one_sample(config, prefix='', frame_list=[100]):\n",
    "def run_one_sample(config, sample, prefix='', frame_list=[100]):\n",
    "\n",
    "    val_agent = Val_pipeline_frontend(config, device=device)\n",
    "    # val_agent.add_net('deepF', net)\n",
    "    # val_agent.add_net('superpointNet', net_SP)\n",
    "    val_agent.load_net_deepF(name='net_deepF')\n",
    "    val_agent.load_net_SP()\n",
    "    val_agent.net_toeval() \n",
    "    iter_max = 100\n",
    "    print(sample['scene_name'], sample['frame_ids'])\n",
    "    val_agent.run_eval(sample, plot_corr_list=plot_corr_list, \n",
    "                   plot_epipolar_list=plot_epipolar_list,\n",
    "                   prefix=prefix, \n",
    "                   save=True, title=False)\n",
    "#         if j >= iter_max:\n",
    "#             break\n",
    "    pass\n",
    "\n",
    "## kitti \n",
    "# run_one_sample(config=change_config(config, iter=1000))\n",
    "# run_one_sample(config=change_config(config, iter=3000))\n",
    "# run_one_sample(config=change_config(config, iter=5000))\n",
    "# run_one_sample(config=change_config(config, iter=8000))\n",
    "\n",
    "# iter_list = [10000, 20000, 30000, 40000, 50000]\n",
    "# iter_list = [1000, 3000, 5000, 8000]\n",
    "# iter_list = [0, 1000, 2000, 3000]\n",
    "iter_list = [0, 200, 400, 600, 800, 1000]\n",
    "\n",
    "# iter_max = 0\n",
    "# sample_list = [0, 1426, 1775]\n",
    "\n",
    "iter_max = 945\n",
    "sample_list = [945]\n",
    "from tqdm import tqdm\n",
    "for j, sample in tqdm(enumerate(val_loader)):\n",
    "    if j in sample_list:\n",
    "        for iter in iter_list:\n",
    "            prefix = f'Sp-Df-f-end-k-freezeDf_s{j}_{iter/1000}k' # 'Sp-Df-fp-end-k'\n",
    "            run_one_sample(config=change_config(config, iter=iter, mode=4), \n",
    "                           sample=sample,\n",
    "                           frame_list=[100], \n",
    "                           prefix=prefix)\n",
    "    if j > iter_max:\n",
    "        break\n",
    "        \n",
    "## apollo\n",
    "# run_one_sample(config=change_config(config, iter=6000, mode=1))\n",
    "# run_one_sample(config=change_config(config, iter=16000, mode=1))\n",
    "# run_one_sample(config=change_config(config, iter=20000, mode=1))\n",
    "# run_one_sample(config=change_config(config, iter=40000, mode=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.eval_tools import Val_pipeline_frontend\n",
    "\n",
    "plot_epipolar_list=[\"mask_conf\", \"mask_epi_dist_gt\"]\n",
    "plot_corr_list=[\"all\"]\n",
    "val_agent = Val_pipeline_frontend(config, device=device)\n",
    "# val_agent.add_net('deepF', net)\n",
    "# val_agent.add_net('superpointNet', net_SP)\n",
    "val_agent.load_net_deepF(name='net_deepF')\n",
    "if config['model']['if_SP']: val_agent.load_net_SP()\n",
    "val_agent.net_toeval() \n",
    "\n",
    "num_list = []\n",
    "iter_max = 2700\n",
    "iter_list = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "iter_list = np.arange(27)*100\n",
    "prefix = 'Si-Df-k' # 'Sp-Df-fp-end-k'\n",
    "for j, sample in enumerate(val_loader):\n",
    "#     val_agent.eval_one_sample(sample)\n",
    "    if j in iter_list:\n",
    "        print(sample['scene_name'], sample['frame_ids'], sample['img_zoom_xy'])\n",
    "        logging.info(f\"eval {j}\")\n",
    "        val_agent.run_eval(sample, plot_epipolar_list=plot_epipolar_list, \n",
    "                           plot_corr_list=plot_corr_list, prefix=prefix, \n",
    "                           save=True)\n",
    "    \n",
    "    \n",
    "    if j >= iter_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New functions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_max = 0\n",
    "for j, sample in enumerate(val_loader):\n",
    "    print(sample['scene_name'], sample['frame_ids'])\n",
    "    val_agent.run_eval(sample)\n",
    "    if j >= iter_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_corrs = []\n",
    "from tqdm import tqdm\n",
    "for j, sample in tqdm(enumerate(train_loader)):\n",
    "    name='matches_all_unique_nums'\n",
    "    num_corrs.append(sample[name].numpy())\n",
    "    if j==200: break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_statistics(arr, name='array'):\n",
    "#     print(f\"{name}: lenght={len(arr)}, mean={arr.mean()}, max={arr.max()}, min={arr.min()}\")\n",
    "\n",
    "from utils.print_tool import print_statistics\n",
    "print_statistics(np.array(num_corrs).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.print_tool import print_dict_attr\n",
    "\n",
    "print_dict_attr(sample, 'shape')\n",
    "print(f\"{np.array(sample['frame_ids']).T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.linspace(150, 300, 200)\n",
    "# b = np.exp(-(a-150)*0.05)\n",
    "# plt.plot(a, b)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing\n",
    "# # sample[\"imgs_grey\"]\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightN_var = torch.tensor(30.)\n",
    "# weightN_mean = torch.tensor(23.0372)\n",
    "# tri_depths = torch.tensor(18.5983)\n",
    "\n",
    "# prob = 1 / torch.sqrt(2*np.pi*weightN_var) * torch.exp(-(tri_depths-weightN_mean)**2 / (2*weightN_var))\n",
    "# print(prob)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import scipy.stats as stats\n",
    "# import math\n",
    "\n",
    "# mu = 23.0372\n",
    "# variance = 30.\n",
    "# sigma = math.sqrt(variance)\n",
    "# x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "# plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_good_utils import (\n",
    "    get_matches_from_SP,\n",
    ")\n",
    "if_SP = config['model']['if_SP']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ori = logits_weights.cpu().numpy().flatten()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(scores_ori, 100)\n",
    "plt.show()\n",
    "\n",
    "N = scores_ori.shape[0]\n",
    "print(N)\n",
    "a_list = []\n",
    "for idx in range(N):\n",
    "    selected_corres_idx = np.random.choice(N, 100, p=scores_ori)\n",
    "    selected_scores = scores_ori[selected_corres_idx]\n",
    "    a_list.append(selected_scores)\n",
    "    \n",
    "a = np.stack(a_list)\n",
    "plt.hist(a.flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "errors = []\n",
    "for topK in range(8, 1000):\n",
    "    w = outs['weights'].cpu().numpy()\n",
    "    pts1 = outs['pts1'].cpu().numpy()\n",
    "    pts2 = outs['pts2'].cpu().numpy()\n",
    "\n",
    "    scores_ori = logits_weights.cpu().numpy().flatten()\n",
    "    sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "    # sort_idxes = np.argsort(epi_res[unique_rows_all_idxes])[::-1]\n",
    "    # scores = scores_ori[unique_rows_all_idxes][sort_idxes\n",
    "    mask_conf = sort_idxes[:topK]\n",
    "    # mask_conf = sort_idxes[:sort_idxes.shape[0]]\n",
    "    # print(scores_ori[unique_rows_all_idxes][mask_conf])\n",
    "\n",
    "    scores_show = scores_ori[unique_rows_all_idxes[mask_conf]]\n",
    "    # scores_show = scores_show - 0.8*np.min(scores_show)\n",
    "    # scores_show = scores_show / np.max(scores_show) * 2. + 0.1\n",
    "#     plt.figure(figsize=(30, 8))\n",
    "#     plt.imshow(img1_rgb)\n",
    "#     plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c=depths_show[mask_conf], s=scores_show*20000+0.5, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "#     plt.colorbar()\n",
    "#     plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c='r', s=np.clip(epi_res[unique_rows_all_idxes][mask_conf]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "#     plt.title('Top 10 corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "#     plt.show()\n",
    "\n",
    "    w_masked = w[:, :, unique_rows_all_idxes[mask_conf]]\n",
    "    pts1_masked = pts1[:, unique_rows_all_idxes[mask_conf], :]\n",
    "    pts2_masked = pts2[:, unique_rows_all_idxes[mask_conf], :]\n",
    "\n",
    "\n",
    "    ## Normalized\n",
    "    from models.DeepFNet import Fit\n",
    "    fitt  = Fit(True, True, True)\n",
    "    out, _= fitt(torch.from_numpy(pts1_masked).cuda(), torch.from_numpy(pts2_masked).cuda(), torch.from_numpy(w_masked).cuda(), if_print=False, matches_good_unique_num=sample['matches_good_unique_nums'])\n",
    "    F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "    # F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "\n",
    "    ## NON-Normalized\n",
    "    # F_my = utils_F._F_from_XY(torch.from_numpy(pts1_masked).cuda().squeeze()[:, :2], torch.from_numpy(pts1_masked).cuda().squeeze()[:, :2], normalize=True)\n",
    "    # F_est_refit = T2.permute(0,2,1).bmm(F_my.unsqueeze(0).bmm(T1)).squeeze().cpu()\n",
    "\n",
    "#     utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][mask_conf, :], x2[unique_rows_all_idxes][mask_conf, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='Ours top 20 with largest score points')\n",
    "\n",
    "    E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "    error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "#     print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "    errors.append(error_Rt_est_ours)\n",
    "#     print(topK, error_Rt_est_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "plt.subplot(211)\n",
    "plt.plot(list(range(8, 1000)), [error[0] for error in errors])\n",
    "plt.xlabel('topK')\n",
    "plt.xticks(list(range(8, 1000, 10)))\n",
    "plt.ylabel('R error')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.grid()\n",
    "plt.subplot(212)\n",
    "plt.plot(list(range(8, 1000)), [error[1] for error in errors])\n",
    "plt.xlabel('topK')\n",
    "plt.xticks(list(range(8, 1000, 10)))\n",
    "plt.ylabel('t error')\n",
    "plt.ylim([0, 5])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_res = utils_F.compute_epi_residual(outs['pts1'], outs['pts2'], torch.inverse(outs['T2'].permute(0,2,1)) @ F_gt_th.unsqueeze(0).cuda() @ torch.inverse(outs['T1'])).unsqueeze(1)\n",
    "epi_res = epi_res.cpu().numpy().flatten()\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "# plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], facecolors='none', s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c='r', s=np.clip(epi_res[unique_rows_all_idxes]*20000, 0., 500), marker='+', linewidths=0.)\n",
    "plt.title('All corres by ours, colored with depth from triangulated GT pose; epi dist in yellow +')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulate points and reproj error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "depth_thres = 200.\n",
    "\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "scale = np.linalg.norm(delta_Rtij[:3, 3:4]) / np.linalg.norm(M_estW[:3, 3:4])\n",
    "\n",
    "# depths, est\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "M2 = np.hstack((M_estW[:3, :3], scale * M_estW[:3, 3:4]))\n",
    "# X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "M2 = delta_Rtij[:3, :]\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_reproj = utils_misc.de_homo_np((K @ M1 @ X_tri_homo).T)\n",
    "x2_reproj = utils_misc.de_homo_np((K @ M2 @ X_tri_homo).T)\n",
    "depths_show = X_tri[-1, unique_rows_all_idxes]\n",
    "depths_show = np.clip(depths_show, 0., depth_thres)\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1_reproj[unique_rows_all_idxes, 0], x1_reproj[unique_rows_all_idxes, 1], c=depths_show, s=20, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.linalg.norm(x1_reproj - x1, ord=2, axis=1)\n",
    "# print(dist)\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.hist(dist, 100)\n",
    "plt.subplot(122)\n",
    "dist_show = np.clip(dist, 0., 2.)\n",
    "plt.hist(dist_show, 100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=depths_show, s=dist_show[unique_rows_all_idxes]*100+0.5, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c='r', s=np.clip(epi_res[unique_rows_all_idxes]*20000, 0., 500), marker='+', linewidths=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = outs['offsets'].cpu().numpy().squeeze().T\n",
    "x1_offsets = offsets[:, :2]\n",
    "x2_offsets = offsets[:, 2:]\n",
    "x1_offsets_norm = np.linalg.norm(x1_offsets, 2, 1)\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[:, 0], x1[:, 1], c='b', s=x1_offsets_norm*20, edgecolors='w', linewidths=2.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_estW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Rtij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2. + 0.05\n",
    "scale = np.linalg.norm(delta_Rtij[:3, 3:4]) / np.linalg.norm(M_estW[:3, 3:4])\n",
    "# depths, est\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R_gt, t_gt))\n",
    "# M2 = np.hstack((R1, t2))\n",
    "# M2 = M_estW\n",
    "M2 = np.hstack((M_estW[:3, :3], scale * M_estW[:3, 3:4]))\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), (x1+x1_offsets).T, (x2+x2_offsets).T)\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "depths_show = X_tri[-1, unique_rows_all_idxes]\n",
    "depths_show = np.clip(depths_show, 0., 200.)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "negative_depth_idx = depths_show==0.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][negative_depth_idx], x1[unique_rows_all_idxes, 1][negative_depth_idx], c='k', \n",
    "            s=200, marker='X', edgecolors='y', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=depths_show, s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.title('All corres by ours, colored with depth from triangulated EST pose; negative in BLACK X')\n",
    "plt.show()\n",
    "\n",
    "epi_res = outs['epi_res_layers'][-1].cpu().numpy().flatten()\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], facecolors='none', s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c='r', s=np.clip(epi_res[unique_rows_all_idxes]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "plt.title('All corres by ours, colored with depth from triangulated EST pose; epi dist in yellow +')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare GT depth and est depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M_estW)\n",
    "print(M_opencv)\n",
    "print(delta_Rtij[:3, :3], delta_Rtij[:3, 3:4] / np.linalg.norm(delta_Rtij[:3, 3:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "depth_thres = 200.\n",
    "\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2. + 0.05\n",
    "scale = np.linalg.norm(delta_Rtij[:3, 3:4]) / np.linalg.norm(M_estW[:3, 3:4])\n",
    "# scale = 1.\n",
    "print(scale)\n",
    "\n",
    "# depths, est\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R_gt, t_gt))\n",
    "# M2 = np.hstack((R1, t2))\n",
    "# M2 = M_estW\n",
    "M2 = np.hstack((M_estW[:3, :3], scale * M_estW[:3, 3:4]))\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "depths_show = X_tri[-1, unique_rows_all_idxes]\n",
    "depths_show = np.clip(depths_show, 0., depth_thres)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "negative_depth_idx = depths_show==0.\n",
    "infinite_depth_idx = depths_show==depth_thres\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][negative_depth_idx], x1[unique_rows_all_idxes, 1][negative_depth_idx], c='k', \n",
    "            s=200, marker='X', edgecolors='y', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][infinite_depth_idx], x1[unique_rows_all_idxes, 1][infinite_depth_idx], c='y', \n",
    "            s=200, marker='X', edgecolors='k', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=depths_show, s=scores_show*20000+0.5, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.title('All corres by ours, colored with depth from triangulated EST pose; negative in BLACK X')\n",
    "plt.show()\n",
    "\n",
    "epi_res = outs['epi_res_layers'][-1].cpu().numpy().flatten()\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "# plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], facecolors='none', s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][negative_depth_idx], x1[unique_rows_all_idxes, 1][negative_depth_idx], c='k', \n",
    "            s=200, marker='X', edgecolors='y', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][infinite_depth_idx], x1[unique_rows_all_idxes, 1][infinite_depth_idx], c='y', \n",
    "            s=200, marker='X', edgecolors='k', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c='r', s=np.clip(epi_res[unique_rows_all_idxes]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "plt.title('All corres by ours, colored with depth from triangulated EST pose; epi dist in yellow +')\n",
    "plt.show()\n",
    "\n",
    "# depths, gt\n",
    "# scale = 1./np.linalg.norm(delta_Rtij[:3, 3:4])\n",
    "scale = 1.\n",
    "\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R_gt, t_gt))\n",
    "# M2 = np.hstack((R1, t2))\n",
    "# M2 = M_estW\n",
    "# M2 = delta_Rtij[:3]\n",
    "M2 = np.hstack((delta_Rtij[:3, :3], delta_Rtij[:3, 3:4]*scale))\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "depth_show = X_tri[-1, unique_rows_all_idxes]\n",
    "depth_show = np.clip(depths_show, 0., 200.)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "negative_depth_idx = depths_show==0.\n",
    "infinite_depth_idx = depths_show==depth_thres\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][negative_depth_idx], x1[unique_rows_all_idxes, 1][negative_depth_idx], c='k', \n",
    "            s=200, marker='X', edgecolors='y', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][infinite_depth_idx], x1[unique_rows_all_idxes, 1][infinite_depth_idx], c='y', \n",
    "            s=200, marker='X', edgecolors='k', linewidths=2.)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=depths_show, s=scores_show*20000, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "# for i in range(x1.shape[0]):\n",
    "#     plt.text(x1[i, 0], x1[i, 1], str(i), color='r', fontsize=10, fontweight='extra bold')\n",
    "plt.title('All corres by ours, colored with depth from triangulated GT pose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.DeepFNet import Fit\n",
    "# fitt  = Fit(True, True, True)\n",
    "# out, _= fitt(outs['pts1'], outs['pts2'], outs['weights'], if_print=False)\n",
    "# out, residual = fitt(outs['pts1'], outs['pts2'], outs['weights'], if_print=False)\n",
    "\n",
    "epi_res = utils_F.compute_epi_residual(outs['pts1'], outs['pts2'], torch.inverse(outs['T2'].permute(0,2,1)) @ F_gt_th.unsqueeze(0).cuda() @ torch.inverse(outs['T1'])).unsqueeze(1)\n",
    "epi_res = epi_res.cpu().numpy().flatten()\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "# plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], facecolors='none', s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c='r', s=np.clip(epi_res[unique_rows_all_idxes]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "plt.title('All corres by ours, colored with depth from triangulated GT pose; epi dist in yellow +')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_gt_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abs and rel depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale = np.linalg.norm(delta_Rtij[:3, 3:4])\n",
    "# scale = 1.\n",
    "# depths, est\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R_gt, t_gt))\n",
    "# M2 = np.hstack((R1, t2))\n",
    "# M2 = M_estW\n",
    "M2 = np.hstack((M_estW[:3, :3], scale * M_estW[:3, 3:4]))\n",
    "print(np.linalg.norm(M2[:3, 3:4]))\n",
    "\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri_est = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "# depths, gt\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R_gt, t_gt))\n",
    "# M2 = np.hstack((R1, t2))\n",
    "# M2 = M_estW\n",
    "# M2 = delta_Rtij[:3]\n",
    "M2 = np.hstack((delta_Rtij[:3, :3], delta_Rtij[:3, 3:4]))\n",
    "\n",
    "print(np.linalg.norm(M2[:3, 3:4]))\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri_gt = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "# Absolute depth\n",
    "X_tri = X_tri_gt - X_tri_est\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "depths_show = X_tri[-1, unique_rows_all_idxes]\n",
    "depths_show = np.clip(depths_show, -50., 50.)\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2. + 0.4\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=depths_show, s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.bwr)\n",
    "plt.colorbar()\n",
    "plt.title('[Absolute depth error] All corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "plt.show()\n",
    "\n",
    "# Relative depth\n",
    "X_tri_gt = np.clip(X_tri_gt, 0., 100.)\n",
    "# X_tri_est = np.clip(X_tri_est, 0., 100.)\n",
    "X_tri = (X_tri_gt - X_tri_est) / (np.abs(X_tri_gt) + 1e-10)\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "depths_show = X_tri[-1, unique_rows_all_idxes]\n",
    "depths_show = np.clip(depths_show, -0.2, 0.2)\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2. + 0.5\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=depths_show, s=scores_show*20000+1., edgecolors='w', linewidths=2., cmap=cm.bwr)\n",
    "plt.colorbar()\n",
    "plt.title('[Relative depth error] All corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# All our scores\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=scores_show*20000+1., c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('All corres by ours')\n",
    "plt.show()\n",
    "\n",
    "# Scores of top ours\n",
    "N = mask_sample.shape[0]\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "mask_conf = sort_idxes[:N]\n",
    "scores_show = scores_ori[unique_rows_all_idxes][mask_conf]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], s=scores_show*20000+1., c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Top %d(inlier num by OpenCV) by Ours'%N)\n",
    "plt.show()\n",
    "\n",
    "# Scores of top OpenCV\n",
    "scores_show = scores_ori[mask_sample]\n",
    "scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[mask_sample, 0], x1[mask_sample, 1], s=scores_show*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Top %d by OpenCV'%N)\n",
    "plt.show()\n",
    "\n",
    "# Geo dists\n",
    "geo_dists = np.sqrt(utils_F._sym_epi_dist(F_gt_th, torch.from_numpy(x1[unique_rows_all_idxes]), torch.from_numpy(x2[unique_rows_all_idxes])).numpy())\n",
    "# plt.hist(geo_dists, 100)\n",
    "# plt.show()\n",
    "geo_dists = np.clip(geo_dists, 0, 10.)\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=geo_dists*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.show()\n",
    "\n",
    "# All corres\n",
    "utils_vis.draw_corr(img1_rgb, img2_rgb, x1[unique_rows_all_idxes], x2[unique_rows_all_idxes], linewidth=0., title='All corres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with subset(top) corres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "errors = []\n",
    "for topK in range(8, 1000):\n",
    "    w = outs['weights'].cpu().numpy()\n",
    "    pts1 = outs['pts1'].cpu().numpy()\n",
    "    pts2 = outs['pts2'].cpu().numpy()\n",
    "\n",
    "    scores_ori = logits_weights.cpu().numpy().flatten()\n",
    "    sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "    # sort_idxes = np.argsort(epi_res[unique_rows_all_idxes])[::-1]\n",
    "    # scores = scores_ori[unique_rows_all_idxes][sort_idxes\n",
    "    mask_conf = sort_idxes[:topK]\n",
    "    # mask_conf = sort_idxes[:sort_idxes.shape[0]]\n",
    "    # print(scores_ori[unique_rows_all_idxes][mask_conf])\n",
    "\n",
    "    scores_show = scores_ori[unique_rows_all_idxes[mask_conf]]\n",
    "    # scores_show = scores_show - 0.8*np.min(scores_show)\n",
    "    # scores_show = scores_show / np.max(scores_show) * 2. + 0.1\n",
    "#     plt.figure(figsize=(30, 8))\n",
    "#     plt.imshow(img1_rgb)\n",
    "#     plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c=depths_show[mask_conf], s=scores_show*20000+0.5, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "#     plt.colorbar()\n",
    "#     plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c='r', s=np.clip(epi_res[unique_rows_all_idxes][mask_conf]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "#     plt.title('Top 10 corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "#     plt.show()\n",
    "\n",
    "    w_masked = w[:, :, unique_rows_all_idxes[mask_conf]]\n",
    "    pts1_masked = pts1[:, unique_rows_all_idxes[mask_conf], :]\n",
    "    pts2_masked = pts2[:, unique_rows_all_idxes[mask_conf], :]\n",
    "\n",
    "\n",
    "    ## Normalized\n",
    "    from models.DeepFNet import Fit\n",
    "    fitt  = Fit(True, True, True)\n",
    "    out, _= fitt(torch.from_numpy(pts1_masked).cuda(), torch.from_numpy(pts2_masked).cuda(), torch.from_numpy(w_masked).cuda(), if_print=False, matches_good_unique_num=sample['matches_good_unique_nums'])\n",
    "    F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "    # F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "\n",
    "    ## NON-Normalized\n",
    "    # F_my = utils_F._F_from_XY(torch.from_numpy(pts1_masked).cuda().squeeze()[:, :2], torch.from_numpy(pts1_masked).cuda().squeeze()[:, :2], normalize=True)\n",
    "    # F_est_refit = T2.permute(0,2,1).bmm(F_my.unsqueeze(0).bmm(T1)).squeeze().cpu()\n",
    "\n",
    "#     utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][mask_conf, :], x2[unique_rows_all_idxes][mask_conf, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='Ours top 20 with largest score points')\n",
    "\n",
    "    E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "    error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "#     print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "    errors.append(error_Rt_est_ours)\n",
    "    print(topK, error_Rt_est_ours)\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(40, 20))\n",
    "plt.subplot(211)\n",
    "plt.plot(list(range(8, 1000)), [error[0] for error in errors])\n",
    "plt.xlabel('topK')\n",
    "plt.xticks(list(range(8, 1000, 10)))\n",
    "plt.ylabel('R error')\n",
    "plt.ylim([0, 5])\n",
    "plt.grid()\n",
    "plt.subplot(212)\n",
    "plt.plot(list(range(8, 1000)), [error[1] for error in errors])\n",
    "plt.xlabel('topK')\n",
    "plt.xticks(list(range(8, 1000, 10)))\n",
    "plt.ylabel('t error')\n",
    "plt.ylim([0, 5])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "w = outs['weights'].cpu().numpy()\n",
    "pts1 = outs['pts1'].cpu().numpy()\n",
    "pts2 = outs['pts2'].cpu().numpy()\n",
    "\n",
    "scores_ori = logits_weights.cpu().numpy().flatten()\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "# sort_idxes = np.argsort(epi_res[unique_rows_all_idxes])[::-1]\n",
    "# scores = scores_ori[unique_rows_all_idxes][sort_idxes\n",
    "mask_conf = sort_idxes[:10]\n",
    "# mask_conf = sort_idxes[:sort_idxes.shape[0]]\n",
    "# print(scores_ori[unique_rows_all_idxes][mask_conf])\n",
    "\n",
    "scores_show = scores_ori[unique_rows_all_idxes[mask_conf]]\n",
    "# scores_show = scores_show - 0.8*np.min(scores_show)\n",
    "# scores_show = scores_show / np.max(scores_show) * 2. + 0.1\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c=depths_show[mask_conf], s=scores_show*20000+0.5, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c='r', s=np.clip(epi_res[unique_rows_all_idxes][mask_conf]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "plt.title('Top 10 corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "plt.show()\n",
    "\n",
    "w_masked = w[:, :, unique_rows_all_idxes[mask_conf]]\n",
    "pts1_masked = pts1[:, unique_rows_all_idxes[mask_conf], :]\n",
    "pts2_masked = pts2[:, unique_rows_all_idxes[mask_conf], :]\n",
    "\n",
    "\n",
    "## Normalized\n",
    "from models.DeepFNet import Fit\n",
    "fitt  = Fit(True, True, True)\n",
    "out, _= fitt(torch.from_numpy(pts1_masked).cuda(), torch.from_numpy(pts2_masked).cuda(), torch.from_numpy(w_masked).cuda(), if_print=False, matches_good_unique_num=sample['matches_good_unique_nums'])\n",
    "F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "# F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "\n",
    "## NON-Normalized\n",
    "# F_my = utils_F._F_from_XY(torch.from_numpy(pts1_masked).cuda().squeeze()[:, :2], torch.from_numpy(pts1_masked).cuda().squeeze()[:, :2], normalize=True)\n",
    "# F_est_refit = T2.permute(0,2,1).bmm(F_my.unsqueeze(0).bmm(T1)).squeeze().cpu()\n",
    "\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][mask_conf, :], x2[unique_rows_all_idxes][mask_conf, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='Ours top 20 with largest score points')\n",
    "\n",
    "E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_weights = outs['weights'].cpu().numpy()\n",
    "pts1 = outs['pts1'].cpu().numpy()\n",
    "pts2 = outs['pts2'].cpu().numpy()\n",
    "\n",
    "logits_weights[0, 0, 187] = 0.\n",
    "\n",
    "scores_ori = logits_weights.flatten()\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "# sort_idxes = np.argsort(epi_res[unique_rows_all_idxes])[::-1]\n",
    "# scores = scores_ori[unique_rows_all_idxes][sort_idxes\n",
    "# mask_conf = sort_idxes[:300]\n",
    "mask_conf = sort_idxes[:sort_idxes.shape[0]]\n",
    "# print(scores_ori[unique_rows_all_idxes][mask_conf])\n",
    "\n",
    "\n",
    "scores_show = scores_ori[unique_rows_all_idxes[mask_conf]]\n",
    "# scores_show = scores_show - 0.8*np.min(scores_show)\n",
    "scores_show = scores_show / np.max(scores_show) * 2. + 0.1\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c=depths_show[mask_conf], s=scores_show*50, edgecolors='w', linewidths=2., cmap=cm.bwr)\n",
    "plt.colorbar()\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c='r', s=np.clip(epi_res[unique_rows_all_idxes][mask_conf]*20000+1., 0., 500), marker='+', linewidths=0.)\n",
    "plt.title('Top 10 corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "plt.show()\n",
    "\n",
    "w_masked = logits_weights\n",
    "pts1_masked = pts1\n",
    "pts2_masked = pts2\n",
    "\n",
    "out, _= fitt(torch.from_numpy(pts1_masked).cuda(), torch.from_numpy(pts2_masked).cuda(), torch.from_numpy(w_masked).cuda(), if_print=False)\n",
    "F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "# F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][:30, :], x2[unique_rows_all_idxes][:30, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='Ours top 20 with largest score points')\n",
    "\n",
    "E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "scale = np.linalg.norm(delta_Rtij[:3, 3:4])\n",
    "# scale = np.linalg.norm(delta_Rtij[:3, 3:4]) / np.linalg.norm(M_estW[:3, 3:4])\n",
    "\n",
    "# depths, est\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = M_estW\n",
    "M2 = np.hstack((M_estW[:3, :3], scale * M_estW[:3, 3:4]))\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri_est = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "# depths, gt\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = delta_Rtij[:3]\n",
    "M2 = np.hstack((delta_Rtij[:3, :3], delta_Rtij[:3, 3:4]))\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri_gt = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "X_tri = X_tri_gt - X_tri_est\n",
    "X_tri_rel = (X_tri_gt - X_tri_est) / (np.abs(X_tri_gt) + 1e-10)\n",
    "\n",
    "# depth_diff = X_tri[-1, :]\n",
    "depth_diff = X_tri_rel[-1, :]\n",
    "# depth_diff_idx = np.abs(depth_diff) > 0.15\n",
    "depth_diff_idx = X_tri_est[-1, :] <= 0.\n",
    "depth_diff_idx = np.logical_or(X_tri_est[-1, :] <= 0., X_tri_est[-1, :] >200.)\n",
    "# depth_diff_idx = scores_ori < 0.001\n",
    "\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "depths_show = X_tri_rel[-1, unique_rows_all_idxes]\n",
    "depths_show = np.clip(depths_show, -0.4, 0.4)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from models.DeepFNet import Fit\n",
    "fitt  = Fit(True, True, True)\n",
    "out, _= fitt(outs['pts1'], outs['pts2'], outs['weights'], if_print=False)\n",
    "F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "# F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][mask_conf, :], x2[unique_rows_all_idxes][mask_conf, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='[Before removal] Ours top 20 with largest score points')\n",
    "E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('[Before removal] Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "\n",
    "w = outs['weights'].cpu().numpy()\n",
    "plt.hist(w.flatten(), 100)\n",
    "plt.show()\n",
    "w[:, :, depth_diff_idx] = 0.\n",
    "plt.hist(w.flatten(), 100)\n",
    "plt.show()\n",
    "\n",
    "# w[:, :, :] = 0.\n",
    "out, _= fitt(outs['pts1'], outs['pts2'], torch.from_numpy(w).cuda(), if_print=False)\n",
    "F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "# F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "\n",
    "scores_after = w.flatten()\n",
    "sort_idxes_after = np.argsort(scores_after[unique_rows_all_idxes])[::-1]\n",
    "mask_conf_after = sort_idxes_after[:20]\n",
    "\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][mask_conf_after, :], x2[unique_rows_all_idxes][mask_conf_after, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='[After removal] Ours top 20 with largest score points')\n",
    "\n",
    "E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('[After removal] Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "keep_idx = np.logical_not(depth_diff_idx)\n",
    "depths_show = X_tri_est[-1, :]\n",
    "depths_show = np.clip(depths_show, 0., 800.)\n",
    "\n",
    "scores_show = scores_after\n",
    "# scores_show = scores_show / np.max(scores_show) * 2. + 0.0\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[keep_idx, 0], x1[keep_idx, 1], c=depths_show[keep_idx], s=scores_show[keep_idx]*20000+1, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.title('[After removal] All corres by ours, colored with EST depth from triangulated GT and EST pose; size is the score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different weight patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = outs['weights'].cpu().numpy()\n",
    "pts1 = outs['pts1'].cpu().numpy()\n",
    "pts2 = outs['pts2'].cpu().numpy()\n",
    "\n",
    "scores_ori = logits_weights.cpu().numpy().flatten()\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "# scores = scores_ori[unique_rows_all_idxes][sort_idxes\n",
    "mask_conf = sort_idxes[:9]\n",
    "print(scores_ori[unique_rows_all_idxes][mask_conf])\n",
    "\n",
    "scores_show = scores_ori[unique_rows_all_idxes[mask_conf]]\n",
    "scores_show = scores_show - 0.8*np.min(scores_show)\n",
    "scores_show = scores_show / np.max(scores_show) * 2. + 0.0\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], c=depths_show[mask_conf], s=scores_show*50, edgecolors='w', linewidths=2., cmap=cm.bwr)\n",
    "plt.colorbar()\n",
    "plt.title('Top 10 corres by ours, colored with depth DIFFERENCE from triangulated GT and EST pose; size is the score')\n",
    "plt.show()\n",
    "\n",
    "w_masked = w[:, :, unique_rows_all_idxes[mask_conf]]\n",
    "pts1_masked = pts1[:, unique_rows_all_idxes[mask_conf], :]\n",
    "pts2_masked = pts2[:, unique_rows_all_idxes[mask_conf], :]\n",
    "\n",
    "out, _= fitt(torch.from_numpy(pts1_masked).cuda(), torch.from_numpy(pts2_masked).cuda(), torch.from_numpy(w_masked).cuda(), if_print=False)\n",
    "F_est_refit = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1']))[0].cpu()\n",
    "# F_est_refit = outs['T2'].permute(0,2,1).bmm(outs['F_est'].bmm(outs['T1']))[0].cpu()\n",
    "\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[unique_rows_all_idxes][mask_conf, :], x2[unique_rows_all_idxes][mask_conf, :], img1_rgb, img2_rgb, F_gt, F_est_refit, im_shape=im_shape, title_append='Ours top 20 with largest score points')\n",
    "\n",
    "E_ests_refit = Ks.transpose(1, 2) @ F_est_refit.cuda() @ Ks\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_ests_refit.cpu().numpy(), E_gt, F_est_refit.cpu().numpy(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale= 1./np.linalg.norm(delta_Rtij[:3, 3:4])\n",
    "scale = 1.\n",
    "print(scale)\n",
    "\n",
    "X = Xs[1].squeeze().numpy() * scale\n",
    "\n",
    "delta_Rtij_camid = np.hstack((delta_Rtij[:3, :3], scale*delta_Rtij[:3, 3:4]))\n",
    "param_list = [K, img1_rgb.shape]\n",
    "\n",
    "N_velo = 100000\n",
    "choice_all = utils_misc.crop_or_pad_choice(X.shape[0], N_velo, shuffle=True)\n",
    "sample_Xj = X[choice_all]\n",
    "# sample_Xj = X\n",
    "delta_Rtij_camid = np.linalg.inv(utils_misc.Rt_pad(delta_Rtij_camid))\n",
    "_, xi = utils_vis.reproj_and_scatter(utils_misc.Rt_depad(delta_Rtij_camid), sample_Xj, img1_rgb, visualize=True, title_appendix='j to i', param_list=param_list, debug=False, s=10)\n",
    "_, xj = utils_vis.reproj_and_scatter(utils_misc.identity_Rt(), sample_Xj, img2_rgb, visualize=True, title_appendix='j to j', param_list=param_list, debug=False, s=10)\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi[:, 0], xi[:, 1], c='r', s=50, edgecolors='w', linewidths=2., cmap=cm.bwr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1_virt_ori.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(utils_misc.homo_np(x2) @ F_gt @ utils_misc.homo_np(x1).T)\n",
    "# print(utils_misc.homo_np(xj) @ F_gt @ utils_misc.homo_np(xi).T)\n",
    "pts1_velo_ori = torch.from_numpy(utils_misc.homo_np(xi)).cuda().unsqueeze(0)\n",
    "pts2_velo_ori = torch.from_numpy(utils_misc.homo_np(xj)).cuda().unsqueeze(0)\n",
    "\n",
    "losses = utils_F.compute_epi_residual(pts1_velo_ori, pts2_velo_ori, sample['F'].cuda(), 0.02) #- res.mean()\n",
    "\n",
    "print(losses.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Fake lidar motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquaternion import Quaternion\n",
    "\n",
    "q_fake = Quaternion(axis=[0., 1., 0.], degrees=0.)\n",
    "R_fake = q_fake.rotation_matrix\n",
    "# t_fake = np.zeros((3, 1))\n",
    "t_fake = np.array([0., 0.00, -1.]).reshape(3, 1)\n",
    "# t_fake = np.array([0.1, 0., 0.]).reshape(3, 1)\n",
    "\n",
    "X = Xs[0].squeeze().numpy()\n",
    "print(X.shape)\n",
    "N_velo = 200\n",
    "choice_all = utils_misc.crop_or_pad_choice(X.shape[0], N_velo, shuffle=True)\n",
    "sample_X = X[choice_all]\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "delta_Rtij_camid = np.hstack((R_fake, t_fake))\n",
    "param_list = [K, img1_rgb.shape]\n",
    "_, xi = utils_vis.reproj_and_scatter(utils_misc.identity_Rt(), sample_X, img1_rgb, visualize=True, title_appendix='j to i', param_list=param_list, debug=False, s=10)\n",
    "_, xj = utils_vis.reproj_and_scatter(delta_Rtij_camid, sample_X, img1_rgb, visualize=True, title_appendix='i to j', param_list=param_list, debug=False, s=10)\n",
    "\n",
    "N_velo = xi.shape[0]\n",
    "E_gt, F_gt = utils_F.E_F_from_Rt_np(R_fake, t_fake, K)\n",
    "\n",
    "delta_Rtij_inv = np.linalg.inv(utils_misc.Rt_pad(np.hstack((R_fake, t_fake))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize: Perfect points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_th = torch.from_numpy(xi).float()\n",
    "xj_th = torch.from_numpy(xj).float()\n",
    "\n",
    "from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "norm_K = NormalizeAndExpand_K(False, True)\n",
    "pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "\n",
    "fit_velo  = Fit(False, True, True)\n",
    "out_velo, _= fit_velo(pts1.cuda().transpose(1, 2), pts2.cuda().transpose(1, 2), torch.ones((1, 1, N_velo)).float().cuda(), if_print=False)\n",
    "F_est_refit = T2.permute(0,2,1).bmm(out_velo.cpu().bmm(T1)).squeeze()\n",
    "print(F_est_refit.numpy())\n",
    "utils_vis.show_epipolar_rui_gtEst(xj, xi, img2_rgb, img2_rgb, F_gt.T, F_est_refit.t(), im_shape=im_shape, title_append='')\n",
    "\n",
    "# Triangulation\n",
    "E_est_refit = utils_F._F_to_E(F_est_refit, K_th)\n",
    "R2s, t2s, M2s = utils_F._get_M2s(E_est_refit)\n",
    "print(delta_Rtij[:3])\n",
    "print(R2s[0].numpy(), R2s[1].numpy())\n",
    "print(t2s[0].numpy(), t2s[1].numpy())\n",
    "# M2_list, error_Rt, Rt_cam = utils_F._E_to_M(E_est_refit, K, xi, xj, inlier_mask=None, delta_Rt_gt=delta_Rtij_inv)\n",
    "        \n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "M2 = np.hstack((R2s[1].numpy(), t2s[1].numpy()))\n",
    "\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), xi.T, xj.T)\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "import matplotlib.cm as cm\n",
    "depths_show = X_tri[-1, :]\n",
    "# depths_show = np.clip(depths_show, 0., 80.)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(depths_show, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi[:, 0], xi[:, 1], c=depths_show, s=100., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "for i in range(N_velo):\n",
    "    plt.text(xi[i, 0], xi[i, 1]-10, str(i), color='r', fontsize=20, fontweight='extra bold')\n",
    "plt.colorbar()\n",
    "# plt.title('All corres by ours, colored with depth from triangulated EST pose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F_est_refit.numpy() / F_est_refit.numpy()[2, 2])\n",
    "print(F_gt / F_gt[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1_eval = (T1 @ pts1_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "pts2_eval = (T2 @ pts2_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "losses = utils_F.compute_epi_residual(pts1_eval, pts2_eval, torch.inverse(T2.permute(0,2,1)) @ F_est_refit @ torch.inverse(T1), loss_params['clamp_at'])\n",
    "print(losses.mean().numpy())\n",
    "\n",
    "# E_est_refit = K_th.t() @ F_est_refit @ K_th\n",
    "E_est_refit = K_th.t() @ F_gt_th @ K_th\n",
    "\n",
    "R2s, t2s, M2s = utils_F._get_M2s(E_est_refit)\n",
    "print('---gt', delta_Rtij[:3, :3], delta_Rtij[:3, 3:4]/np.linalg.norm(delta_Rtij[:3, 3:4]))\n",
    "print('---est R', R2s[0].numpy(), R2s[1].numpy())\n",
    "print('---est t', t2s[0].numpy(), t2s[1].numpy())\n",
    "\n",
    "# M_estW, error_Rt_est_ours = utils_F.goodCorr_eval_nondecompose(xi, xj, E_est_refit.numpy().astype(np.float64), delta_Rtij_inv, K, None, Rt_scene_list=[R2s[1].numpy(), t2s[1].numpy()])\n",
    "M_estW, error_Rt_est_ours = utils_F.goodCorr_eval_nondecompose(xi, xj, E_est_refit.numpy().astype(np.float64), delta_Rtij_inv, K, None, Rt_scene_list=None)\n",
    "\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "print('-=-- Est R, t')\n",
    "print(M_estW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some noise to some point(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inperfect points: sample SIFT kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_velo = 200\n",
    "\n",
    "scores_ori = logits_weights.cpu().numpy().flatten()\n",
    "plt.hist(scores_ori, 100)\n",
    "plt.show()\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "scores = scores_ori[unique_rows_all_idxes][sort_idxes]\n",
    "mask_conf = sort_idxes[:N_velo]\n",
    "\n",
    "plt.hist(scores_ori[unique_rows_all_idxes][mask_conf], 100)\n",
    "plt.show()\n",
    "\n",
    "xi = x1[unique_rows_all_idxes][mask_conf]\n",
    "xj = x2[unique_rows_all_idxes][mask_conf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_thres = -2.\n",
    "max_thres = 2.\n",
    "\n",
    "xi_noise = xi.copy()\n",
    "xj_noise = xj.copy()\n",
    "noise_idx = 5\n",
    "while True:\n",
    "    noise = np.random.normal(size=(1, 2))\n",
    "    if not(noise[0, 0] < min_thres or noise[0, 1] < min_thres or noise[0, 0] > max_thres or noise[0, 1] > max_thres):\n",
    "        break\n",
    "print(noise)\n",
    "# xi_noise[noise_idx] = xi_noise[noise_idx] + noise\n",
    "\n",
    "xi_th = torch.from_numpy(xi_noise).float()\n",
    "xj_th = torch.from_numpy(xj_noise).float()\n",
    "\n",
    "from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "norm_K = NormalizeAndExpand_K(False, True)\n",
    "pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "\n",
    "fit_velo  = Fit(False, True, True)\n",
    "out_velo, _= fit_velo(pts1.cuda().transpose(1, 2), pts2.cuda().transpose(1, 2), torch.ones((1, 1, N_velo)).float().cuda(), if_print=False)\n",
    "F_est_refit_noise = T2.permute(0,2,1).bmm(out_velo.cpu().bmm(T1)).squeeze()\n",
    "# print(out_velo.cpu().squeeze().numpy() / out_velo.cpu().squeeze().numpy()[2, 2])\n",
    "\n",
    "# F_my = utils_F._F_from_XY(pts1.squeeze().t()[:, :2], pts2.squeeze().t()[:, :2], normalize=True)\n",
    "# # print(F_my.numpy() / F_my.numpy()[2, 2])\n",
    "# F_est_refit_noise = T2.permute(0,2,1).bmm(F_my.unsqueeze(0).bmm(T1)).squeeze()\n",
    "\n",
    "# Errors\n",
    "pts1_eval = (T1 @ pts1_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "pts2_eval = (T2 @ pts2_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "losses = utils_F.compute_epi_residual(pts1_eval, pts2_eval, torch.inverse(T2.permute(0,2,1)) @ F_est_refit_noise @ torch.inverse(T1), loss_params['clamp_at'])\n",
    "print(losses.mean().numpy())\n",
    "\n",
    "E_est_refit = utils_F._F_to_E(F_est_refit_noise, K_th)\n",
    "M_estW, error_Rt_est_ours = utils_F.goodCorr_eval_nondecompose(xi_noise, xj_noise, E_est_refit.numpy().astype(np.float64), delta_Rtij_inv, K, None)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "# Visualization\n",
    "# utils_vis.show_epipolar_rui_gtEst(xj, xi, img2_rgb, img1_rgb, F_gt.T, F_est_refit.t(), im_shape=im_shape, title_append='Noiseless')\n",
    "utils_vis.show_epipolar_rui_gtEst(xj_noise, xi_noise, img2_rgb, img1_rgb, F_gt.T, F_est_refit_noise.t(), im_shape=im_shape, title_append='With Noise', emphasis_idx=[noise_idx], label_text=True)\n",
    "\n",
    "# Triangulation\n",
    "# R2s, t2s, M2s = utils_F._get_M2s(E_est_refit)\n",
    "# print(delta_Rtij[:3])\n",
    "# print(R2s[0].numpy(), R2s[1].numpy())\n",
    "# print(t2s[0].numpy(), t2s[1].numpy())\n",
    "# # M2_list, error_Rt, Rt_cam = utils_F._E_to_M(E_est_refit, K, xi, xj, inlier_mask=None, delta_Rt_gt=delta_Rtij_inv)\n",
    "        \n",
    "# M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R2s[1].numpy(), t2s[1].numpy()))\n",
    "\n",
    "# X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), xi_noise.T, xj_noise.T)\n",
    "# X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "# import matplotlib.cm as cm\n",
    "# depths_show = X_tri[-1, :]\n",
    "# # depths_show = np.clip(depths_show, 0., 80.)\n",
    "# # plt.figure(figsize=(30, 2))\n",
    "# # plt.hist(depths_show, 200)\n",
    "# # plt.show()\n",
    "\n",
    "# plt.figure(figsize=(30, 8))\n",
    "# plt.imshow(img1_rgb)\n",
    "# plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c=depths_show, s=100., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "# for i in range(N_velo):\n",
    "#     plt.text(xi_noise[i, 0], xi_noise[i, 1]-10, str(i), color='r', fontsize=20, fontweight='extra bold')\n",
    "# plt.colorbar()\n",
    "# # plt.title('All corres by ours, colored with depth from triangulated EST pose')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Where are good points that if moves a bit gives least errors?] Generate noises and get error stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Rtij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Rtij_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_idx  = 10\n",
    "\n",
    "plt.figure()\n",
    "min_thres = -2.\n",
    "max_thres = 2.\n",
    "scale = 1.\n",
    "for tries in range(1000):\n",
    "#     print(noise_idx, tries)\n",
    "    xi_noise = xi.copy()\n",
    "    xj_noise = xj.copy()\n",
    "    while True:\n",
    "        noise = np.random.normal(scale=scale, size=(1, 2))\n",
    "        if not(noise[0, 0] < min_thres or noise[0, 1] < min_thres or noise[0, 0] > max_thres or noise[0, 1] > max_thres):\n",
    "            break\n",
    "            \n",
    "    xi_noise[noise_idx] = xi_noise[noise_idx] + noise\n",
    "    plt.scatter(xi_noise[noise_idx][0], xi_noise[noise_idx][1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "\n",
    "error_list = {}\n",
    "for noise_idx in range(N_velo):\n",
    "    error_list[str(noise_idx)] = [[], [], []]\n",
    "\n",
    "for noise_idx in range(N_velo):\n",
    "    for tries in range(1---):\n",
    "        print(noise_idx, tries)\n",
    "        xi_noise = xi.copy()\n",
    "        xj_noise = xj.copy()\n",
    "        \n",
    "        while True:\n",
    "            noise = np.random.normal(scale=scale, size=(1, 2))\n",
    "            if not(noise[0, 0] < min_thres or noise[0, 1] < min_thres or noise[0, 0] > max_thres or noise[0, 1] > max_thres):\n",
    "                break\n",
    "            \n",
    "        xi_noise[noise_idx] = xi_noise[noise_idx] + noise\n",
    "        \n",
    "        weight = torch.ones((1, 1, N_velo))\n",
    "#         weight[:, :, noise_idx] = 0.\n",
    "\n",
    "        xi_th = torch.from_numpy(xi_noise).float()\n",
    "        xj_th = torch.from_numpy(xj_noise).float()\n",
    "\n",
    "        norm_K = NormalizeAndExpand_K(False, True)\n",
    "        pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "\n",
    "        fit_velo  = Fit(False, True, True)\n",
    "        out_velo, _= fit_velo(pts1.cuda().transpose(1, 2), pts2.cuda().transpose(1, 2), weight.float().cuda(), if_print=False)\n",
    "        F_est_refit_noise = T2.permute(0,2,1).bmm(out_velo.cpu().bmm(T1)).squeeze()\n",
    "#         F_my = utils_F._F_from_XY(pts1.squeeze().t()[:, :2], pts2.squeeze().t()[:, :2], normalize=True)\n",
    "#         F_est_refit_noise = T2.permute(0,2,1).bmm(F_my.unsqueeze(0).bmm(T1)).squeeze()\n",
    "\n",
    "        # Errors\n",
    "        pts1_eval = (T1 @ pts1_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "        pts2_eval = (T2 @ pts2_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "        losses = utils_F.compute_epi_residual(pts1_eval, pts2_eval, torch.inverse(T2.permute(0,2,1)) @ F_est_refit_noise @ torch.inverse(T1), loss_params['clamp_at'])\n",
    "#         print(losses.mean().numpy())\n",
    "\n",
    "        E_est_refit = utils_F._F_to_E(F_est_refit_noise, K_th)\n",
    "        M_estW, error_Rt_est_ours = utils_F.goodCorr_eval_nondecompose(xi_noise, xj_noise, E_est_refit.numpy().astype(np.float64), delta_Rtij_inv, K, None, Rt_scene_list=None)\n",
    "#         print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "        \n",
    "        error_list[str(noise_idx)][0].append(error_Rt_est_ours[0])\n",
    "        error_list[str(noise_idx)][1].append(error_Rt_est_ours[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stats_dict = {}\n",
    "for noise_idx in range(N_velo):\n",
    "    all_R_errors = error_list[str(noise_idx)][0]\n",
    "    all_t_errors = error_list[str(noise_idx)][1]\n",
    "    error_stats_dict[str(noise_idx)] = {'R_mean': np.mean(all_R_errors), 'R_std': np.std(all_R_errors), \\\n",
    "                                        't_mean': np.mean(all_t_errors), 't_std': np.std(all_t_errors), \\\n",
    "                                       'R_med': np.median(all_R_errors), 't_med': np.median(all_t_errors)}\n",
    "\n",
    "R_means = [error_stats_dict[str(idx)]['R_mean'] for idx in range(N_velo)]\n",
    "t_means = [error_stats_dict[str(idx)]['t_mean'] for idx in range(N_velo)]\n",
    "R_stds = [error_stats_dict[str(idx)]['R_std'] for idx in range(N_velo)]\n",
    "t_stds = [error_stats_dict[str(idx)]['t_std'] for idx in range(N_velo)]\n",
    "R_meds = [error_stats_dict[str(idx)]['R_med'] for idx in range(N_velo)]\n",
    "t_meds = [error_stats_dict[str(idx)]['t_med'] for idx in range(N_velo)]\n",
    "\n",
    "scale = 0.5\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(R_meds)*10000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('R_med 10X')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(t_meds)*1000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('t_med')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(R_means)*10000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('R_mean 10X')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(t_means)*1000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('t_mean')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(R_stds)*10000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('R_std 10X')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(t_stds)*1000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('t_std')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise to all points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_th = torch.from_numpy(xi).float()\n",
    "xj_th = torch.from_numpy(xj).float()\n",
    "from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "norm_K = NormalizeAndExpand_K(False, True)\n",
    "pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "\n",
    "\n",
    "min_thres = -1.5\n",
    "max_thres = 1.5\n",
    "\n",
    "xi_noise = xi.copy()\n",
    "xj_noise = xj.copy()\n",
    "# noise_idx = 12\n",
    "# while True:\n",
    "noise = np.clip(np.random.normal(scale=1., size=(N_velo, 2)), min_thres, max_thres)\n",
    "#     if not(noise[0, 0] < min_thres or noise[0, 1] < min_thres or noise[0, 0] > max_thres or noise[0, 1] > max_thres):\n",
    "#         break\n",
    "xi_noise = xi_noise + noise\n",
    "\n",
    "xi_th = torch.from_numpy(xi_noise).float()\n",
    "xj_th = torch.from_numpy(xj_noise).float()\n",
    "\n",
    "from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "norm_K = NormalizeAndExpand_K(False, True)\n",
    "pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Rtij_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for idx in range(10000):\n",
    "    print(idx)\n",
    "    xi_th = torch.from_numpy(xi).float()\n",
    "    xj_th = torch.from_numpy(xj).float()\n",
    "    from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "    norm_K = NormalizeAndExpand_K(False, True)\n",
    "    pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "\n",
    "    dists = torch.norm(pts1[:, :2, :], p=2, dim=1, keepdim=True)\n",
    "#     sort_idxes = np.argsort(dists.numpy().flatten())[::-1] # largest\n",
    "    sort_idxes = np.argsort(dists.numpy().flatten()) # smallest\n",
    "    print(dists.numpy()[:, :, sort_idxes[:10]])\n",
    "\n",
    "    xi_noise = xi.copy()\n",
    "    xj_noise = xj.copy()\n",
    "\n",
    "    N_noise = 200\n",
    "    min_thres = -50.\n",
    "    max_thres = 50.\n",
    "    noise_i = np.clip(np.random.normal(scale=3, size=(N_noise, 2)), min_thres, max_thres)\n",
    "    noise_j = np.clip(np.random.normal(scale=3, size=(N_noise, 2)), min_thres, max_thres)\n",
    "#     plt.scatter(noise[:, 0], noise[:, 1])\n",
    "#     plt.show()\n",
    "\n",
    "    xi_noise[sort_idxes[:N_noise]] = xi_noise[sort_idxes[:N_noise]] + noise_i\n",
    "    xj_noise[sort_idxes[:N_noise]] = xj_noise[sort_idxes[:N_noise]] + noise_j\n",
    "#     xi_noise = xi_noise + noise_i\n",
    "#     xj_noise = xj_noise + noise_j\n",
    "\n",
    "    xi_th = torch.from_numpy(xi_noise).float()\n",
    "    xj_th = torch.from_numpy(xj_noise).float()\n",
    "    pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     weights = torch.ones((1, 1, N_velo))\n",
    "    # weights = torch.nn.functional.normalize(torch.norm(pts1[:, :2, :], p=2, dim=1, keepdim=True), p=1, dim=2)\n",
    "    # weights = -weights + torch.max(weights)\n",
    "    # weights = torch.nn.functional.normalize(1./torch.norm(pts1[:, :2, :], p=2, dim=1, keepdim=True), p=1, dim=2)\n",
    "    \n",
    "    weights = np.zeros((1, 1, N_velo))\n",
    "    weights[:, :, sort_idxes[:N_noise]] = 1.\n",
    "    weights = torch.from_numpy(weights).float()\n",
    "\n",
    "    # weights[:, :, [14, 17, 2]] = 0.\n",
    "    # print(weights)\n",
    "\n",
    "    # fit_velo  = Fit(False, True, True)\n",
    "    # out_velo, _= fit_velo(pts1.cuda().transpose(1, 2), pts2.cuda().transpose(1, 2), weights.float().cuda(), if_print=False)\n",
    "    # F_est_refit_noise = T2.permute(0,2,1).bmm(out_velo.cpu().bmm(T1)).squeeze()\n",
    "    # print(out_velo.cpu().squeeze().numpy() / out_velo.cpu().squeeze().numpy()[2, 2])\n",
    "\n",
    "    F_my = utils_F._F_from_XY(pts1.squeeze().t()[:, :2], pts2.squeeze().t()[:, :2], torch.diag(weights.float().squeeze()), normalize=True)\n",
    "    # print(F_my.numpy() / F_my.numpy()[2, 2])\n",
    "    F_est_refit_noise = T2.permute(0,2,1).bmm(F_my.unsqueeze(0).bmm(T1)).squeeze()\n",
    "\n",
    "    # Errors\n",
    "    pts1_eval = (T1 @ pts1_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "    pts2_eval = (T2 @ pts2_virt_ori.permute(0,2,1).cpu()).permute(0,2,1)\n",
    "    losses = utils_F.compute_epi_residual(pts1_eval, pts2_eval, torch.inverse(T2.permute(0,2,1)) @ F_est_refit_noise @ torch.inverse(T1), loss_params['clamp_at'])\n",
    "    print(losses.mean().numpy())\n",
    "\n",
    "    E_est_refit = utils_F._F_to_E(F_est_refit_noise, K_th)\n",
    "    M_estW, error_Rt_est_ours = utils_F.goodCorr_eval_nondecompose(xi_noise, xj_noise, E_est_refit.numpy().astype(np.float64), delta_Rtij_inv, K, None)\n",
    "    print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "    error_list.append(error_Rt_est_ours)\n",
    "\n",
    "    # Visualization\n",
    "    # utils_vis.show_epipolar_rui_gtEst(xj, xi, img2_rgb, img1_rgb, F_gt.T, F_est_refit.t(), im_shape=im_shape, title_append='Noiseless')\n",
    "#     utils_vis.show_epipolar_rui_gtEst(xj_noise, xi_noise, img2_rgb, img1_rgb, F_gt.T, F_est_refit_noise.t(), im_shape=im_shape, title_append='With Noise', label_text=False)\n",
    "\n",
    "    # Triangulation\n",
    "    # R2s, t2s, M2s = utils_F._get_M2s(E_est_refit)\n",
    "    # print(delta_Rtij[:3])\n",
    "    # print(R2s[0].numpy(), R2s[1].numpy())\n",
    "    # print(t2s[0].numpy(), t2s[1].numpy())\n",
    "    # # M2_list, error_Rt, Rt_cam = utils_F._E_to_M(E_est_refit, K, xi, xj, inlier_mask=None, delta_Rt_gt=delta_Rtij_inv)\n",
    "\n",
    "    # M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    # M2 = np.hstack((R2s[1].numpy(), t2s[1].numpy()))\n",
    "\n",
    "    # X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), xi_noise.T, xj_noise.T)\n",
    "    # X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "    # import matplotlib.cm as cm\n",
    "    # depths_show = X_tri[-1, :]\n",
    "    # # depths_show = np.clip(depths_show, 0., 80.)\n",
    "    # # plt.figure(figsize=(30, 2))\n",
    "    # # plt.hist(depths_show, 200)\n",
    "    # # plt.show()\n",
    "    \n",
    "    if idx==0:\n",
    "        plt.figure(figsize=(30, 8))\n",
    "        plt.imshow(img1_rgb)\n",
    "        plt.scatter(xi_noise[:, 0], xi_noise[:, 1], s=weights.squeeze().numpy()*100., edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "    #     for i in range(N_velo):\n",
    "    #         plt.text(xi_noise[i, 0], xi_noise[i, 1]-10, str(i), color='r', fontsize=20, fontweight='extra bold')\n",
    "    #     plt.colorbar()\n",
    "        plt.title('All corres by ours, colored with depth from triangulated EST pose')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(noise_i[:, 0], noise_i[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rs = [err[0] for err in error_list]\n",
    "err_ts = [err[1] for err in error_list]\n",
    "\n",
    "print(np.mean(err_rs), np.median(err_rs), np.std(err_rs))\n",
    "print(np.mean(err_ts), np.median(err_ts), np.std(err_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise to each point; measure epi_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DeepFNet import NormalizeAndExpand_K, Fit\n",
    "\n",
    "error_list = {}\n",
    "for noise_idx in range(N_velo):\n",
    "    error_list[str(noise_idx)] = []\n",
    "    \n",
    "min_thres = -4.\n",
    "max_thres = 4.\n",
    "scale = 2.\n",
    "\n",
    "for noise_idx in range(N_velo):\n",
    "    for tries in range(100):\n",
    "        print(noise_idx, tries)\n",
    "        xi_noise = xi.copy()\n",
    "        xj_noise = xj.copy()\n",
    "        \n",
    "        while True:\n",
    "            noise = np.random.normal(scale=scale, size=(1, 2))\n",
    "            if not(noise[0, 0] < min_thres or noise[0, 1] < min_thres or noise[0, 0] > max_thres or noise[0, 1] > max_thres):\n",
    "                break\n",
    "            \n",
    "        xi_noise[noise_idx] = xi_noise[noise_idx] + noise\n",
    "        \n",
    "        while True:\n",
    "            noise = np.random.normal(scale=scale, size=(1, 2))\n",
    "            if not(noise[0, 0] < min_thres or noise[0, 1] < min_thres or noise[0, 0] > max_thres or noise[0, 1] > max_thres):\n",
    "                break\n",
    "            \n",
    "        xj_noise[noise_idx] = xj_noise[noise_idx] + noise\n",
    "        \n",
    "        weight = torch.ones((1, 1, N_velo))\n",
    "#         weight[:, :, noise_idx] = 0.\n",
    "\n",
    "        xi_th = torch.from_numpy(xi_noise).float()\n",
    "        xj_th = torch.from_numpy(xj_noise).float()\n",
    "\n",
    "        norm_K = NormalizeAndExpand_K(False, True)\n",
    "        pts1, pts2, T1, T2 = norm_K(torch.cat((xi_th, xj_th), 1).unsqueeze(0), sample['K_inv']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "        \n",
    "        F_gt_normalize = torch.inverse(T2.permute(0,2,1)) @ F_gt_th @ torch.inverse(T1)\n",
    "        epi_res = utils_F.compute_epi_residual(pts1.transpose(1, 2), pts2.transpose(1, 2), F_gt_normalize).unsqueeze(1)\n",
    "        \n",
    "        error_list[str(noise_idx)].append(epi_res.squeeze()[noise_idx].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stats_dict = {}\n",
    "for noise_idx in range(N_velo):\n",
    "    all_epis = error_list[str(noise_idx)]\n",
    "    error_stats_dict[str(noise_idx)] = {'epi_mean': np.mean(all_epis), 'epi_std': np.std(all_epis), 'epi_med': np.median(all_epis)}\n",
    "\n",
    "epi_means = [error_stats_dict[str(idx)]['epi_mean'] for idx in range(N_velo)]\n",
    "epi_stds = [error_stats_dict[str(idx)]['epi_std'] for idx in range(N_velo)]\n",
    "epi_meds = [error_stats_dict[str(idx)]['epi_med'] for idx in range(N_velo)]\n",
    "\n",
    "scale = 5\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(epi_meds)*10000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('epi_med 10X')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(epi_means)*10000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('epi_mean 10X')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(xi_noise[:, 0], xi_noise[:, 1], c='r', s=np.array(epi_stds)*10000*scale, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.title('epi_std 10X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From reproj lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_lidar = sample['pts1_velo'].squeeze().numpy()[:, :2]\n",
    "x2_lidar = sample['pts2_velo'].squeeze().numpy()[:, :2]\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1_lidar[:, 0], x1_lidar[:, 1], c='r')\n",
    "plt.title('Reproj lidr points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['scene_name'], sample['frame_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8, suppress=True)\n",
    "delta_P = sample['releative_scene_poses'][1].numpy()[0]\n",
    "delta_R = delta_P[:3, :3]\n",
    "print(delta_R)\n",
    "print(np.linalg.det(delta_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8, suppress=True)\n",
    "\n",
    "# R2s, t2s, M2s = utils_F._get_M2s(E_gt_th)\n",
    "R2s, t2s, M2s = utils_F._get_M2s(torch.from_numpy(E_est))\n",
    "\n",
    "R1, R2 = R2s[0].numpy(), R2s[1].numpy()\n",
    "t1, t2 = t2s[0].numpy(), t2s[1].numpy()\n",
    "t1 = t1 / np.linalg.norm(t1)\n",
    "t2 = t2 / np.linalg.norm(t2)\n",
    "print('R1:', R1, np.linalg.det(R1))\n",
    "print('R2:', R2, np.linalg.det(R2))\n",
    "\n",
    "R_gt = delta_Rtij[:3, :3]\n",
    "t_gt = delta_Rtij[:3, 3:4]\n",
    "t_gt = t_gt / np.linalg.norm(t_gt)\n",
    "print('---R_gt: ', R_gt, np.linalg.det(R_gt))\n",
    "# from scipy.linalg import qr\n",
    "# Q, R = qr(R_gt)\n",
    "# print (Q.dot(Q.T))\n",
    "\n",
    "U, S, V = np.linalg.svd(R1)\n",
    "R_test = U@V\n",
    "print('---R_test: ', R_test, np.linalg.det(R_test))\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "q1 = Quaternion(matrix=R1)\n",
    "print('===q1')\n",
    "print(q1)\n",
    "print(q1.degrees, q1.axis)\n",
    "q2 = Quaternion(matrix=R2)\n",
    "print('===q2')\n",
    "print(q2)\n",
    "print(q2.degrees, q1.axis)\n",
    "\n",
    "# q = Quaternion(matrix=R2.T @ R1)\n",
    "# print(q.degrees, q.axis)\n",
    "\n",
    "print('===q_gt')\n",
    "q_gt = Quaternion(matrix=R_gt)\n",
    "print(q_gt, q_gt.axis)\n",
    "\n",
    "def q_to_array(q):\n",
    "    return np.array([q.real, q.imaginary[0], q.imaginary[1], q.imaginary[2]])\n",
    "\n",
    "print('--L2 dists between (q1, q_gt), (q2, q_gt):')\n",
    "n1 = np.linalg.norm(q_to_array(q_gt) - q_to_array(q1))\n",
    "n2 = np.linalg.norm(q_to_array(q_gt) - q_to_array(q2))\n",
    "print(n1, n2)\n",
    "\n",
    "print('--L2 dists between (t1, t_gt), (t2, t_gt):')\n",
    "n1 = np.linalg.norm(t_gt - t1)\n",
    "n2 = np.linalg.norm(t_gt - t2)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q_to_array(q_gt), q_gt.axis, q_gt.degrees)\n",
    "print(q_to_array(q1), q1.axis, q1.degrees)\n",
    "print(q_to_array(q2), q2.axis, q2.degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1.T)\n",
    "print(t2.T)\n",
    "print(t_gt.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, F = utils_F._E_F_from_Rt(torch.from_numpy(delta_Rtij_inv[:3, :3]), torch.from_numpy(delta_Rtij_inv[:3, 3:4]), K_th, tensor_input=True)\n",
    "print(E.numpy().T)\n",
    "print(E_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulate points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_gt, R_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_estW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depths, est\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "# M2 = np.hstack((R_gt, t_gt))\n",
    "M2 = np.hstack((R2, t2))\n",
    "# M2 = M_estW\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "scores_show = X_tri[-1, unique_rows_all_idxes]\n",
    "scores_show = np.clip(scores_show, 0., 80.)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(scores_show, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=scores_show, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.title('All corres by ours, colored with depth from triangulated EST pose')\n",
    "plt.show()\n",
    "\n",
    "# depths, gt\n",
    "M1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "M2 = np.hstack((R_gt, t_gt))\n",
    "# M2 = np.hstack((R1, t2))\n",
    "# M2 = M_estW\n",
    "X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "scores_show = X_tri[-1, unique_rows_all_idxes]\n",
    "scores_show = np.clip(scores_show, 0., 80.)\n",
    "plt.figure(figsize=(30, 2))\n",
    "plt.hist(scores_show, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], c=scores_show, edgecolors='w', linewidths=2., cmap=cm.plasma)\n",
    "plt.colorbar()\n",
    "plt.title('All corres by ours, colored with depth from triangulated GT pose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with imaginary pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_estW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_test, F_test = utils_F.E_F_from_Rt_np(M_estW[:3, :3], delta_Rtij[:3, 3:4], sample['K'][0].numpy())\n",
    "# E_test, F_test = utils_F.E_F_from_Rt_np(delta_Rtij[:3, :3], M_estW[:3, 3:4], sample['K'][0].numpy())\n",
    "\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[mask_conf, :], x2[mask_conf, :], img1_rgb, img2_rgb, F_gt, F_est, im_shape=im_shape, title_append='Ours top50 with largest score points')\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[mask_conf, :], x2[mask_conf, :], img1_rgb, img2_rgb, F_gt, F_test, im_shape=im_shape, title_append='Ours top50 with largest score points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['K'].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Rtij[:3, :3], delta_Rtij[:3, 3:4], sample['K']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All our scores\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=scores_show*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('All corres by ours')\n",
    "plt.show()\n",
    "\n",
    "# Scores of top ours\n",
    "N = mask_sample.shape[0]\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "mask_conf = sort_idxes[:N]\n",
    "scores_show = scores_ori[unique_rows_all_idxes][mask_conf]\n",
    "scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], s=scores_show*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Top %d(inlier num by OpenCV) by Ours'%N)\n",
    "plt.show()\n",
    "\n",
    "# Scores of top OpenCV\n",
    "scores_show = scores_ori[mask_sample]\n",
    "scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[mask_sample, 0], x1[mask_sample, 1], s=scores_show*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Top %d by OpenCV'%N)\n",
    "plt.show()\n",
    "\n",
    "# Geo dists\n",
    "geo_dists = np.sqrt(utils_F._sym_epi_dist(F_gt_th, torch.from_numpy(x1[unique_rows_all_idxes]), torch.from_numpy(x2[unique_rows_all_idxes])).numpy())\n",
    "# plt.hist(geo_dists, 100)\n",
    "# plt.show()\n",
    "geo_dists = np.clip(geo_dists, 0, 10.)\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=geo_dists*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.show()\n",
    "\n",
    "# All corres\n",
    "utils_vis.draw_corr(img1_rgb, img2_rgb, x1[unique_rows_all_idxes], x2[unique_rows_all_idxes], linewidth=0., title='All corres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much does out learned weights explain these corres (by showing the SVD res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DeepFNet import NormalizeAndExpand_K\n",
    "is_cuda = True\n",
    "is_test = False\n",
    "\n",
    "\n",
    "# norm_K = NormalizeAndExpand_K(is_cuda, is_test)\n",
    "fit = Fit(is_cuda, is_test)\n",
    "\n",
    "# pts = data_batch['matches_xy_ori']\n",
    "# pts1, pts2, T1, T2 = norm_K(pts, data_batch['K_invs']) # pts: [b, N, 2] # \\in [-1, 1]\n",
    "# pts1 = pts1.permute(0,2,1)\n",
    "# pts2 = pts2.permute(0,2,1)\n",
    "\n",
    "out, X, p = fit(outs['pts1'], outs['pts2'], outs['weights'])\n",
    "out = outs['T2'].permute(0,2,1).bmm(out.bmm(outs['T1'])).cpu().numpy()\n",
    "X = X.cpu().numpy() # weighted\n",
    "p = p.cpu().numpy() # un-weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_vec = out.reshape((9, 1))\n",
    "print(F_vec.T)\n",
    "# F_vec = F_gt.reshape((9, 1))\n",
    "A = X.squeeze()\n",
    "res = ((A @ F_vec)**2).flatten()\n",
    "\n",
    "scores_show = res[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=scores_show*5000000000, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('All res by Ours (where we make errors in weighted SVD)')\n",
    "plt.show()\n",
    "\n",
    "scores_show = res[unique_rows_all_idxes][mask_conf]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], s=scores_show*50000000000, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Top %d(inlier num by OpenCV) res by Ours (where in out most conf. ones we make most errors)'%N)\n",
    "plt.show()\n",
    "\n",
    "# All our scores\n",
    "scores_show = scores_ori[unique_rows_all_idxes]\n",
    "scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=scores_show*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Scores of all corres by ours')\n",
    "plt.show()\n",
    "\n",
    "# Scores of top ours\n",
    "N = mask_sample.shape[0]\n",
    "# N = 100\n",
    "sort_idxes = np.argsort(scores_ori[unique_rows_all_idxes])[::-1]\n",
    "mask_conf = sort_idxes[:N]\n",
    "scores_show = scores_ori[unique_rows_all_idxes][mask_conf]\n",
    "scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0][mask_conf], x1[unique_rows_all_idxes, 1][mask_conf], s=scores_show*50, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('Top %d scores(inlier num by OpenCV) by Ours'%N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F_vec = out.reshape((9, 1))\n",
    "F_vec = F_gt.reshape((9, 1))\n",
    "print(F_vec.T)\n",
    "A = p.squeeze()\n",
    "res = ((A @ F_vec)**2).flatten()\n",
    "\n",
    "scores_show = res[unique_rows_all_idxes]\n",
    "# scores_show = scores_show / np.max(scores_show) * 2.\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.imshow(img1_rgb)\n",
    "plt.scatter(x1[unique_rows_all_idxes, 0], x1[unique_rows_all_idxes, 1], s=scores_show*50000, c='r', edgecolors='w', linewidths=2.)\n",
    "plt.title('All res by Ours')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter points with largest res & Understanding the degenerate condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DeepFNet import NormalizeAndExpand_K\n",
    "is_cuda = True\n",
    "is_test = False\n",
    "\n",
    "# norm_K = NormalizeAndExpand_K(is_cuda, is_test)\n",
    "fit = Fit(is_cuda, is_test)\n",
    "\n",
    "E_recover, X, p = fit(outs['pts1'], outs['pts2'], outs['weights'])\n",
    "F_recover = outs['T2'].permute(0,2,1).bmm(E_recover.bmm(outs['T1']))\n",
    "print(F_recover.cpu().numpy().squeeze())\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_recover.cpu().numpy().squeeze(), E_gt, F_recover.cpu().numpy().squeeze(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "# Get reses and filter out weights of largest reses\n",
    "res = (X @ F_recover.view(-1, 9, 1))**2\n",
    "\n",
    "res_rank = np.argsort(res.cpu().numpy().flatten())[::-1]\n",
    "weights_np = outs['weights'].cpu().numpy() # [1, 1, 1000]\n",
    "weights_np[:, :, res_rank[:10]] = 0.\n",
    "# print(weights_np)\n",
    "E_recover2, X, p = fit(outs['pts1'], outs['pts2'], torch.from_numpy(weights_np).cuda())\n",
    "F_recover2 = outs['T2'].permute(0,2,1).bmm(E_recover2.bmm(outs['T1']))\n",
    "print(F_recover2.cpu().numpy().squeeze())\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_recover2.cpu().numpy().squeeze(), E_gt, F_recover2.cpu().numpy().squeeze(), F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delta_Rtij[:3])\n",
    "utils_F._E_to_M(E_recover.squeeze().cpu(), K, x1, x2, inlier_mask=None, delta_Rt_gt=delta_Rtij_inv, show_debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "show_debug = True\n",
    "show_result = True\n",
    "E_est_th = E_recover.squeeze().cpu()\n",
    "depth_thres = 100.\n",
    "delta_Rt_gt = delta_Rtij_inv\n",
    "method_name = 'Ours'\n",
    "\n",
    "if show_debug:\n",
    "    print('--- Recovering pose from E...')\n",
    "count_N = x1.shape[0]\n",
    "R2s, t2s, M2s = utils_F._get_M2s(E_est_th)\n",
    "\n",
    "R1 = np.eye(3)\n",
    "t1 = np.zeros((3, 1))\n",
    "M1 = np.hstack((R1, t1))\n",
    "\n",
    "# Cheirality check following OpenCV implementation: https://github.com/opencv/opencv/blob/808ba552c532408bddd5fe51784cf4209296448a/modules/calib3d/src/five-point.cpp#L513\n",
    "depth_thres = depth_thres\n",
    "cheirality_checks = []\n",
    "M2_list = []\n",
    "error_Rt = ()\n",
    "\n",
    "def within_mask(Z, thres_min, thres_max):\n",
    "    return (Z > thres_min) & (Z < thres_max)\n",
    "\n",
    "X_tri_list = []\n",
    "for Rt_idx, M2 in enumerate(M2s):\n",
    "    M2 = M2.numpy()\n",
    "    R2 = M2[:, :3]\n",
    "    t2 = M2[:, 3:4]\n",
    "    if show_debug:\n",
    "        print(M2)\n",
    "        # print(np.linalg.det(R2))\n",
    "    X_tri_homo = cv2.triangulatePoints(np.matmul(K, M1), np.matmul(K, M2), x1.T, x2.T)\n",
    "    X_tri = X_tri_homo[:3, :]/X_tri_homo[-1, :]\n",
    "    X_tri_list.append(X_tri)\n",
    "    # C1 = -np.matmul(R1, t1) # https://math.stackexchange.com/questions/82602/how-to-find-camera-position-and-rotation-from-a-4x4-matrix\n",
    "    # cheirality1 = np.matmul(R1[2:3, :], (X_tri-C1)).reshape(-1) # https://cmsc426.github.io/sfm/\n",
    "    # if show_debug:\n",
    "    #     print(X_tri[-1, :])\n",
    "    cheirality_mask_1 = within_mask(X_tri[-1, :], 0., depth_thres)\n",
    "\n",
    "    X_tri_cam2 = np.matmul(R2, X_tri) + t2\n",
    "    # C2 = -np.matmul(R2, t2)\n",
    "    # cheirality2 = np.matmul(R2[2:3, :], (X_tri_cam3-C2)).reshape(-1)\n",
    "    cheirality_mask_2 = within_mask(X_tri_cam2[-1, :], 0., depth_thres)\n",
    "\n",
    "    cheirality_mask_12 = cheirality_mask_1 & cheirality_mask_2\n",
    "    cheirality_checks.append(cheirality_mask_12)\n",
    "\n",
    "    if show_debug:\n",
    "        print('%d/%d points passed the check:'%(np.sum(cheirality_mask_12), X_tri.shape[1]))\n",
    "\n",
    "if show_debug:\n",
    "    print([np.sum(mask) for mask in cheirality_checks])\n",
    "\n",
    "good_M_index, non_zero_nums = max(enumerate([np.sum(mask) for mask in cheirality_checks]), key=operator.itemgetter(1))\n",
    "if non_zero_nums > 0:\n",
    "    # Rt_idx = cheirality_checks.index(True)\n",
    "    M_inv = utils_misc.Rt_depad(np.linalg.inv(utils_misc.Rt_pad(M2s[good_M_index].numpy())))\n",
    "    if show_result:\n",
    "        print('The %d_th (0-based) Rt meets the Cheirality Condition! with [R|t] (camera):\\n'%good_M_index, M_inv)\n",
    "\n",
    "    if delta_Rt_gt is not None:\n",
    "        R2 = M2s[good_M_index][:, :3].numpy()\n",
    "        t2 = M2s[good_M_index][:, 3:4].numpy()\n",
    "        # error_R = min([utils_geo.rot12_to_angle_error(R2.numpy(), delta_R_gt) for R2 in R2s])\n",
    "        # error_t = min(utils_geo.vector_angle(t2, delta_t_gt), utils_geo.vector_angle(-t2, delta_t_gt))\n",
    "\n",
    "        R2 = M_inv[:, :3]\n",
    "        t2 = M_inv[:, 3:4]\n",
    "        error_R = utils_geo.rot12_to_angle_error(R2, delta_Rt_gt[:3, :3]) # [RUI] Both of camera motion\n",
    "        error_t = utils_geo.vector_angle(t2, delta_Rt_gt[:3, 3:4])\n",
    "        if show_result:\n",
    "            print('Recovered by %s (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(method_name, error_R, error_t))\n",
    "        error_Rt = (error_R, error_t)\n",
    "\n",
    "else:\n",
    "    # raise ValueError('ERROR! 0 of qualified [R|t] found!')\n",
    "    print('ERROR! 0 of qualified [R|t] found!')\n",
    "    error_Rt = ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('Xs.mat', {'X_tri_list': X_tri_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask center points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 = outs['pts1'].cpu().numpy().squeeze()[:, :2]\n",
    "# p2 = outs['pts2'].cpu().numpy().squeeze()[:, :2]\n",
    "# w = outs['weights'].cpu().numpy().squeeze()\n",
    "\n",
    "# mask_x = np.logical_or(p1[:, 0]<-0.25, p1[:, 0]>0.25)\n",
    "# mask_y = np.logical_or(p1[:, 1]<-0.1, p1[:, 0]>0.1)\n",
    "# mask_xy = np.logical_and(mask_x, mask_y) \n",
    "mask_x = np.logical_and(p1[:, 0]>-0.25, p1[:, 0]<0.25)\n",
    "mask_y = np.logical_and(p1[:, 1]>-0.1, p1[:, 1]<0.1)\n",
    "mask_xy = np.logical_and(mask_x, mask_y) \n",
    "\n",
    "pts1_np = outs['pts1'].cpu().numpy()\n",
    "pts2_np = outs['pts2'].cpu().numpy()\n",
    "weights_np = outs['weights'].cpu().numpy()\n",
    "# out_new, _, _ = fit(outs['pts1'], outs['pts2'], outs['weights'])\n",
    "pts1_new = outs['pts1'].cpu().numpy()[:, np.logical_not(mask_xy), :]\n",
    "pts2_new = outs['pts2'].cpu().numpy()[:, np.logical_not(mask_xy), :]\n",
    "# weights_new = [:, :, mask_xy]\n",
    "weights_np[:, :, mask_xy] = weights_np[:, :, mask_xy] * 0.\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(p1[:, 0], p1[:, 1])\n",
    "plt.subplot(122)\n",
    "plt.scatter(pts1_new[0, :, 0], pts1_new[0, :, 1])\n",
    "plt.show()\n",
    "\n",
    "out_new, _, _ = fit(torch.from_numpy(pts1_np).cuda(), torch.from_numpy(pts2_np).cuda(), torch.from_numpy(weights_np).cuda())\n",
    "F_ests_masked = outs['T2'].permute(0,2,1).bmm(out_new.bmm(outs['T1']))\n",
    "F_est_masked = F_ests_masked.cpu().numpy().squeeze()\n",
    "E_ests_masked = Ks.transpose(1, 2) @ F_ests_masked @ Ks\n",
    "E_est_masked = E_ests_masked.cpu().detach().numpy()[0]\n",
    "\n",
    "\n",
    "print(F_est_mask)\n",
    "print(F_gt)\n",
    "utils_vis.show_epipolar_rui_gtEst(x1[mask_xy, :][:30], x2[mask_xy, :][:30], img1_rgb, img2_rgb, F_gt, F_est_mask, im_shape=im_shape, title_append='Ours top50')\n",
    "\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_est, E_gt, F_est, F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))\n",
    "\n",
    "error_Rt_est_ours, epi_dist_mean_est_ours, _, _, _, _, _, M_estW = val_rt(idx, K, x1, x2, E_est_masked, E_gt, F_est_mask, F_gt, delta_Rtij, five_point=False, if_opencv=False)\n",
    "print('Recovered by ours (camera): The rotation error (degree) %.4f, and translation error (degree) %.4f'%(error_Rt_est_ours[0], error_Rt_est_ours[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fit(nn.Module):\n",
    "    def __init__(self, is_cuda=True, is_test=False):\n",
    "        super(Fit, self).__init__()\n",
    "        # self.svd = bsvd(is_cuda, is_test)\n",
    "\n",
    "        self.ones_b = Variable(torch.ones((1, 1, 1)).float())\n",
    "        self.zero_b = Variable(torch.zeros((1, 1, 1)).float())\n",
    "        self.T_b = torch.zeros(1, 3, 3).float()\n",
    "\n",
    "        self.mask = Variable(torch.ones(3))\n",
    "        self.mask[-1] = 0\n",
    "\n",
    "        if is_cuda:\n",
    "            self.ones_b = self.ones_b.cuda()\n",
    "            self.zero_b = self.zero_b.cuda()\n",
    "            self.T_b = self.T_b.cuda()\n",
    "            self.mask = self.mask.cuda()\n",
    "        self.is_cuda = is_cuda\n",
    "#        self.bsvd = bsvd_torch()\n",
    "\n",
    "    def normalize(self, pts, weights):\n",
    "        device = pts.device\n",
    "        T = Variable(self.T_b.to(device).expand(pts.size(0), 3, 3)).clone()\n",
    "        ones = self.ones_b.to(device).expand(pts.size(0), pts.size(1), 1)\n",
    "\n",
    "        denom = weights.sum(1)\n",
    "        #\n",
    "\n",
    "        # c = torch.mean(pts,1)\n",
    "        # newpts_ = (pts - c.unsqueeze(1))\n",
    "        # meandist = newpts_[:,:,:2].pow(2).sum(2).sqrt().mean(1)\n",
    "\n",
    "        c = torch.sum(pts*weights,1)/denom\n",
    "        # print(c.size(), pts.size())\n",
    "        newpts_ = (pts - c.unsqueeze(1))\n",
    "        meandist = ((weights*(newpts_[:,:,:2].pow(2).sum(2).sqrt().unsqueeze(2))).sum(1)/denom).squeeze(1)\n",
    "\n",
    "        scale = 1.4142/meandist\n",
    "\n",
    "        T[:,0,0] = scale\n",
    "        T[:,1,1] = scale\n",
    "        T[:,2,2] = 1\n",
    "        T[:,0,2] = -c[:,0]*scale\n",
    "        T[:,1,2] = -c[:,1]*scale\n",
    "\n",
    "#        pts_ = torch.cat((pts, ones), 2)\n",
    "        # print(pts.device, weights.device, T.device, self.T_b.device)\n",
    "        pts_out = torch.bmm(T, pts.permute(0,2,1))\n",
    "        return pts_out, T\n",
    "\n",
    "    def weighted_svd(self, pts1, pts2, weights):\n",
    "        device = weights.device\n",
    "        weights = weights.squeeze(1).unsqueeze(2)\n",
    "\n",
    "        ones = torch.ones_like(weights)\n",
    "        if self.is_cuda:\n",
    "            ones = ones.cuda()\n",
    "        pts1n, T1 = self.normalize(pts1, ones)\n",
    "        pts2n, T2 = self.normalize(pts2, ones)\n",
    "        \n",
    "        p = torch.cat((pts2n[:,0].unsqueeze(1)*pts1n,\n",
    "                       pts2n[:,1].unsqueeze(1)*pts1n,\n",
    "                       pts1n), 1).permute(0,2,1)\n",
    "\n",
    "        p = torch.nn.functional.normalize(p, dim=2)\n",
    "\n",
    "        X = p*weights\n",
    "\n",
    "        out_b = []\n",
    "        for b in range(X.size(0)):\n",
    "            _, _, V = torch.svd(X[b])\n",
    "            F = V[:,-1].view(3,3)\n",
    "            U, S, V = torch.svd(F)\n",
    "            F_ = U.mm((S*self.mask.to(device)).diag()).mm(V.t())\n",
    "            out_b.append(F_.unsqueeze(0))\n",
    "\n",
    "        out = torch.cat(out_b, 0)\n",
    "\n",
    "        out = T2.permute(0,2,1).bmm(out).bmm(T1)\n",
    "\n",
    "        return out, X, p\n",
    "\n",
    "    def forward(self, pts1, pts2, weights):\n",
    "        out, X, p = self.weighted_svd(pts1, pts2, weights)\n",
    "\n",
    "        return out, X, p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-deepsfm",
   "language": "python",
   "name": "py36-deepsfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
